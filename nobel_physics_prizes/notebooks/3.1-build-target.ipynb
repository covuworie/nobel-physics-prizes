{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Target\n",
    "\n",
    "As a recap, the [training data](../data/processed/train-physicists-from-1901.csv), [validation data](../data/processed/validation-physicists-from-1901.csv) and [test data](../data/processed/test-physicists-from-1901.csv) contain information on physicists who were eligible to receive a Nobel Prize in Physics. That is, they were alive on and after 10 December 1901, the date the prize was first awarded. \n",
    "\n",
    "All of the physicists in the training data are deceased and all the physicists in the validation and test data are alive. Recall that the Nobel Prize in Physics cannot be awarded posthumously and one of the goals of this project is to try to predict the next Physics Nobel Laureates. As a result, the data was purposely sampled in this way, so that the training set can be used to build models, which predict whether a living physicist is likely to be awarded the Nobel Prize in Physics.\n",
    "\n",
    "It is time to use the training, validation and test data, along with the [Nobel Physics Laureates](../data/raw/nobel-physics-prize-laureates.csv) data, to create the target that indicates whether a physicist is a Physics Nobel Laureate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "\n",
    "First let's read in the training, validation and test data and the list of Nobel Physics Laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_physicists = pd.read_csv('../data/processed/train-physicists-from-1901.csv')\n",
    "train_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_physicists = pd.read_csv('../data/processed/validation-physicists-from-1901.csv')\n",
    "validation_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The double t naming of \"ttest_\" variables in this file is for testing purposes. When `ipytest` cleans the\n",
    "# tests it deletes ANY object in the global namespace that begins with \"test_\", not just functions.\n",
    "ttest_physicists = pd.read_csv('../data/processed/test-physicists-from-1901.csv')\n",
    "ttest_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_physicists = pd.read_csv('../data/raw/nobel-physics-prize-laureates.csv')\n",
    "nobel_physicists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Target\n",
    "\n",
    "It is now time to create the target from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target(full_name, laureate):\n",
    "    \n",
    "    \"\"\"Build the target variable indicating whether the physicist is a Nobel Laureate or not.\n",
    "    \n",
    "    Args:\n",
    "        full_name (pandas.Series): Full name of physicist.\n",
    "        laureate (pandas.Series): Full name of Physics Nobel Laureate.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.Series: Target variable indicating whether the physicist is a Nobel Laureate or not.\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    target = full_name.to_frame(name='full_name')\n",
    "    target['physics_laureate'] = target.full_name.apply(\n",
    "        lambda name: name in laureate.values).map({True: 'yes', False: 'no'})\n",
    "    target = target.set_index('full_name')['physics_laureate']\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = build_target(train_physicists.fullName, nobel_physicists.Laureate)\n",
    "assert((len(train_target) == len(train_physicists)))\n",
    "assert(isinstance(train_target, pd.core.series.Series))\n",
    "assert((train_target == 'yes').sum() == 123)\n",
    "assert(all(train_target.notna()))\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_target = build_target(validation_physicists.fullName, nobel_physicists.Laureate)\n",
    "assert((len(validation_target) == len(validation_physicists)))\n",
    "assert(isinstance(validation_target, pd.core.series.Series))\n",
    "assert((validation_target == 'yes').sum() == 41)\n",
    "assert(all(validation_target.notna()))\n",
    "validation_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_target = build_target(ttest_physicists.fullName, nobel_physicists.Laureate)\n",
    "assert((len(ttest_target) == len(ttest_physicists)))\n",
    "assert(isinstance(ttest_target, pd.core.series.Series))\n",
    "assert((ttest_target == 'yes').sum() == 42)\n",
    "assert(all(ttest_target.notna()))\n",
    "ttest_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what percentage of the physicists in each of the dataframes are laureates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fraction = (train_target == 'yes').sum() / len(train_target)\n",
    "validation_fraction = (validation_target == 'yes').sum() / len(validation_target)\n",
    "ttest_fraction = (ttest_target == 'yes').sum() / len(ttest_target)\n",
    "laureate_fraction = pd.Series(\n",
    "    data=[round(100 * training_fraction, 1), round(100 * validation_fraction, 1),\n",
    "          round(100 * ttest_fraction, 1)],\n",
    "    index=['Training', 'Validation', 'Test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = laureate_fraction.plot(kind='bar', title='Percentage of Laureates')\n",
    "ax.set_ylabel('%', labelpad=10, rotation='horizontal')\n",
    "ax.set_yticks(ticks=np.linspace(0, 40, num=5))\n",
    "ax.tick_params(left=False, bottom=False)\n",
    "plt.xticks(rotation=0)\n",
    "plt.box(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a well balanced proportion of laureates in each of the datasets. There are no real surprises here as it's obvious there are more non-laureates than laureates. Naturally, due to the class imbalance, an appropriate metric for selecting and evaluating models will need to be chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting the Data\n",
    "\n",
    "Now we have the training, validation and test target series, we will persist them for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target.to_csv('../data/processed/train-target.csv', header=True)\n",
    "validation_target.to_csv('../data/processed/validation-target.csv', header=True)\n",
    "ttest_target.to_csv('../data/processed/test-target.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
