{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Target\n",
    "\n",
    "As a recap, the [training data](../data/processed/train-physicists-from-1901.csv), [validation data](../data/processed/validation-physicists-from-1901.csv) and [test data](../data/processed/test-physicists-from-1901.csv) contain information on physicists who were eligible to receive a Nobel Prize in Physics. That is, they were alive on and after 10 December 1901, the date the prize was first awarded. \n",
    "\n",
    "All of the physicists in the training data are deceased and all the physicists in the validation and test data are alive (up to the last 6-18 months since this is the approximate length of time DBpedia data is behind Wikipedia articles). Since one of the goals of this project is to try to predict the next Physics Nobel Laureate(s). The data was purposely sampled in this way as the aim is to use the training set to build models that predict whether a physicist who is still alive has been awarded or is likely to be awarded the *Nobel Prize in Physics*.\n",
    "\n",
    "It is finally time to use the training, validation and test data, along with the [Nobel Physics Laureates](../data/raw/nobel-physics-prize-laureates.csv) collected, in order to create the target which indicates whether a physicist is a *Nobel Laureate in Physics*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "\n",
    "First let's read in the training, validation and test data and the list of Nobel Physics laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_physicists = pd.read_csv('../data/processed/train-physicists-from-1901.csv')\n",
    "train_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_physicists = pd.read_csv(\n",
    "    '../data/processed/validation-physicists-from-1901.csv')\n",
    "validation_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_physicists = pd.read_csv(\n",
    "    '../data/processed/test-physicists-from-1901.csv')\n",
    "test_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_physicists = pd.read_csv('../data/raw/nobel-physics-prize-laureates.csv')\n",
    "nobel_physicists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Target\n",
    "\n",
    "It is now time to create the target from the data I have collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target(full_name, laureate):\n",
    "    target = full_name.to_frame(name='full_name')\n",
    "    target['physics_laureate'] = target.full_name.apply(\n",
    "        lambda name: name in laureate.values).map({True: 'yes', False: 'no'})\n",
    "    target = target.set_index('full_name')['physics_laureate']\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = build_target(train_physicists.fullName, nobel_physicists.Laureate)\n",
    "assert((len(train_target) == len(train_physicists)))\n",
    "assert(isinstance(train_target, pd.core.series.Series))\n",
    "assert((train_target == 'yes').sum() == 123)\n",
    "assert(all(train_target.notna()))\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_target = build_target(validation_physicists.fullName,\n",
    "                                 nobel_physicists.Laureate)\n",
    "assert((len(validation_target) == len(validation_physicists)))\n",
    "assert(isinstance(validation_target, pd.core.series.Series))\n",
    "assert((validation_target == 'yes').sum() == 41)\n",
    "assert(all(validation_target.notna()))\n",
    "validation_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = build_target(test_physicists.fullName, nobel_physicists.Laureate)\n",
    "assert((len(test_target) == len(test_physicists)))\n",
    "assert(isinstance(test_target, pd.core.series.Series))\n",
    "assert((test_target == 'yes').sum() == 42)\n",
    "assert(all(test_target.notna()))\n",
    "test_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what percentage of the physicists in each of the dataframes are laureates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fraction = (train_target == 'yes').sum() / len(train_target)\n",
    "validation_fraction = (validation_target == 'yes').sum() / len(validation_target)\n",
    "test_fraction = (test_target == 'yes').sum() / len(test_target)\n",
    "laureate_fraction = pd.Series(\n",
    "    data=[round(100 * training_fraction, 1), round(100 * validation_fraction, 1),\n",
    "          round(100 * test_fraction, 1)],\n",
    "    index=['Training', 'Validation', 'Test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = laureate_fraction.plot(kind='bar', title='Percentage of Laureates')\n",
    "ax.set_ylabel('%', labelpad=10, rotation='horizontal')\n",
    "ax.set_yticks(ticks=np.linspace(0, 40, num=5))\n",
    "ax.tick_params(left=False, bottom=False)\n",
    "plt.xticks(rotation=0)\n",
    "plt.box(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a well balanced proportion of laureates in each of the datasets. There are no real surprises here as it's obvious there are more non-laureates than laureates. Naturally, due to the class imbalance, an appropriate metric for selecting and evaluating models will need to be chosen during model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting the Data\n",
    "\n",
    "Now I have the training, validation and test target series, I'll persist them for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target.to_csv('../data/processed/train-target.csv', header=True)\n",
    "validation_target.to_csv('../data/processed/validation-target.csv', header=True)\n",
    "test_target.to_csv('../data/processed/test-target.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
