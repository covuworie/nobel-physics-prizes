{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Physicists\n",
    "\n",
    "As well as the list of [Nobel Physics Laureates](../data/raw/nobel-physics-prize-laureates.csv), we will need a list of physicists who are notable for their achievements, but have not won the Nobel Prize in Physics. Wikipedia contains two lists of physicists who are notable for their achievements - one general [list of physicists](https://en.wikipedia.org/w/index.php?title=List_of_physicists&oldid=864677795) and another [list of theoretical physicists](https://en.wikipedia.org/w/index.php?title=List_of_theoretical_physicists&oldid=855745137). We will scrape these lists, combine them with the list of laureates and unify all of the physicists into a single list. The entire analysis of this project will be based on the data that is acquired on these physicists. OK time to get scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Environment\n",
    "\n",
    "An initialization step is needed to setup the environment:\n",
    "\n",
    "- The locale needs to be set for all categories to the userâ€™s default setting (typically specified in the LANG environment variable) to enable correct sorting of physicists names with accents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from src.data.url_utils import urls_progress_bar\n",
    "from src.data.wiki_utils import BLACKLIST_LINKS\n",
    "from src.data.wiki_utils import SECTION_TITLES\n",
    "from src.data.wiki_utils import WIKI_OLD_URL\n",
    "from src.data.wiki_utils import get_linked_article_titles\n",
    "from src.data.wiki_utils import get_redirected_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "\n",
    "First let's read in the Nobel Physics Laureates into a [pandas](https://pandas.pydata.org/) dataframe, remove the missing values and convert this to a list of laureate names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_laureates = pd.read_csv('../data/raw/nobel-physics-prize-laureates.csv')\n",
    "physics_laureates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_laureates = physics_laureates.Laureate.dropna().values.tolist()\n",
    "assert(len(physics_laureates) == 207)\n",
    "physics_laureates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Physicists\n",
    "\n",
    "We will use a combination of [requests](http://docs.python-requests.org/en/master/) and [beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to scrape the links of physicist names from the Wikipedia pages above. In the future we will need these links in order to fetch data about the physicists from [DBpedia](https://wiki.dbpedia.org/about). An important point to note is that we will actually need to send HTTP requests to fetch the linked pages as some of them redirect to different URLs. The tricky part is that the redirects are done via javascript, so they are not detected by requests. As a result, we will have to parse the javascript to find the redirect link. Even after all of this, some of the redirected Wikipedia links do not match the DBpedia links, resulting in the wrong resource being retrieved. To avoid this, we manually force the correct redirects using a [wikipedia redirects cache](../data/raw/wikipedia-redirects.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notable_physicists(laureates, title_cache_path=None, progress_bar=None):\n",
    "    \"\"\"Get a list of notable physicists.\n",
    "    Args:\n",
    "        laureates (list of `str`): Nobel Physics Laureates.\n",
    "        title_cache_path (str, optional): Defaults to None. Path of the csv file\n",
    "            where the title cache of known mappings is located.\n",
    "        progress_bar (progressbar.ProgressBar): Progress bar.\n",
    "\n",
    "    Returns:\n",
    "        list (str): List of names of notable physicists.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # read in the cache\n",
    "    if title_cache_path:\n",
    "        cache = pd.read_csv(title_cache_path)\n",
    "        redirected_titles = dict(zip(cache.name, cache.redirect_name))\n",
    "    \n",
    "    # get the theoretical physicists\n",
    "    theoretical_physicists = get_linked_article_titles(\n",
    "        WIKI_OLD_URL + 'List_of_theoretical_physicists&oldid=855745137', section_titles=SECTION_TITLES)\n",
    "    assert(len(theoretical_physicists) == 267)\n",
    "\n",
    "    # get the physicists\n",
    "    physicists = get_linked_article_titles(\n",
    "        WIKI_OLD_URL + 'List_of_physicists&oldid=861832841', section_titles=list(string.ascii_uppercase),\n",
    "        blacklist_links=BLACKLIST_LINKS)\n",
    "    assert(len(physicists) == 976)\n",
    "    assert(not set(BLACKLIST_LINKS).intersection(set(physicists)))\n",
    "\n",
    "    # merge the lists with the laureates list\n",
    "    notable_physicists = list(set(theoretical_physicists + physicists + laureates))\n",
    "\n",
    "    # get the redirect title (if any) from a HTTP request\n",
    "    notable_physicists = get_redirected_titles(\n",
    "        notable_physicists, title_cache_path=title_cache_path, max_workers=20, progress_bar=progress_bar)\n",
    "\n",
    "    # remove duplicates, sort and return list\n",
    "    notable_physicists = list(set(notable_physicists.values()))\n",
    "    for name, redirect_name in redirected_titles.items():\n",
    "        if (locale.strcoll(name, redirect_name) != 0 and name in notable_physicists and \n",
    "            redirect_name in notable_physicists):\n",
    "            notable_physicists.remove(name)\n",
    "    \n",
    "    notable_physicists.sort(key=locale.strxfrm)\n",
    "    return notable_physicists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_URLS = 1127\n",
    "title_cache_path = '../data/raw/wikipedia-redirects.csv'\n",
    "notable_physicists = get_notable_physicists(physics_laureates, title_cache_path=title_cache_path,\n",
    "                                            progress_bar=urls_progress_bar(NUM_URLS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that there are no duplicate names and how many names we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(notable_physicists) == 1069)\n",
    "assert(len(np.unique(notable_physicists)) == len(notable_physicists))\n",
    "len(notable_physicists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the list to a file for future use and check the list of names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/physicists.txt', mode='w', encoding='utf-8') as file:\n",
    "    file.writelines('\\n'.join(notable_physicists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat ../data/raw/physicists.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
