{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Nobel Prize Laureates\n",
    "\n",
    "We will begin by scraping a [Wikipedia](https://en.wikipedia.org/wiki/Main_Page) list of [Nobel Laureates in Physics from 1901 - 2017](https://en.wikipedia.org/w/index.php?title=List_of_Nobel_laureates_in_Physics&oldid=862097595). Nobel Laureates in Chemistry are included in the nomination process for the Nobel Prize in Physics. Some of them had or have a professional or personal relationship with one or more Physics Nobel Laureates. Therefore, to examine how these relationships possibly affect the awarding of the Nobel Prize in Physics, we will also scrape a Wikipedia list of [Nobel Laureates in Chemistry from 1901 - 2017](https://en.wikipedia.org/w/index.php?title=List_of_Nobel_laureates_in_Chemistry&oldid=860639110). You should recognize a few of the more famous names on both lists, even if you do not recognize them all. OK time to get scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment\n",
    "\n",
    "An initialization step is needed to setup the environment:\n",
    "- An environment variable needs to be set to disable loading of `user-config.py` for [pywikibot](https://github.com/wikimedia/pywikibot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PYWIKIBOT_NO_USER_CONFIG=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywikibot as pwb\n",
    "import wikitextparser as wtp\n",
    "\n",
    "from src.data.url_utils import urls_progress_bar\n",
    "from src.data.wiki_utils import FORCED_REDIRECTS\n",
    "from src.data.wiki_utils import get_redirected_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Nobel Physics Laureates\n",
    "\n",
    "We will use a combination of [pywikibot](https://github.com/wikimedia/pywikibot) and [wikitextparser](https://github.com/5j9/wikitextparser) to scrape the laureates data from the tables in the Wikipedia pages above and store it in a [pandas](https://pandas.pydata.org/) dataframe. In the future we will need to fetch data about the physicists from [DBpedia](https://wiki.dbpedia.org/about) using the links in the table, so [requests](http://docs.python-requests.org/en/master/) and [beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) will be used to obtain these. An important point to note is that we will actually need to send HTTP requests to fetch the linked pages as some of them redirect to different URLs. The tricky part is that the redirects are done via javascript, so they are not detected by requests. As a result, we will have to parse the javascript to find the redirect link. Even after all of this, some of the redirected Wikipedia links do not match the DBpedia links, resulting in the wrong resource being retrieved. To avoid this, we manually force the correct redirects now.\n",
    "\n",
    "Let's start with the physics laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nobel_laureates(code='en', fam='wikipedia',\n",
    "                        title='List of Nobel laureates in Physics',\n",
    "                        oldid=None):\n",
    "    \"\"\"Get a table of Nobel Laureates from Wikipedia.\n",
    "\n",
    "     Args:\n",
    "         code (str): Language code as defined by `pywikibot`.\n",
    "         fam (str): Family name or object as defined by `pywikibot`.\n",
    "         title (str): The title of the Wikipedia page as defined by `pywikibot`.\n",
    "             This is essentially the path name to the url with any underscores\n",
    "             replaced by spaces.\n",
    "             e.g. `https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Physics`\n",
    "             has title `List of Nobel laureates in Physics`.\n",
    "        oldid (int): The revid of the revision of the page desired. \n",
    "\n",
    "    Returns:\n",
    "        pandas.Dataframe: Dataframe containing the table information.\n",
    "\n",
    "    \"\"\"\n",
    "    site = pwb.Site(code=code, fam=fam)\n",
    "    return _get_nobel_laureates(site, title, oldid=oldid)\n",
    "\n",
    "\n",
    "def _get_nobel_laureates(site, title, oldid=None):\n",
    "    code = _get_page_wikicode(site, title, oldid=oldid)\n",
    "    table = code.tables[0].data()\n",
    "    laureates = pd.DataFrame(table[1:], columns=[\n",
    "        'Year', 'Image', 'Laureate', 'Country', 'Rationale', 'Ref'])\n",
    "    return laureates\n",
    "\n",
    "\n",
    "def _get_page_wikicode(site, page_title, oldid=None):\n",
    "    page = pwb.Page(site, page_title)\n",
    "    if oldid:\n",
    "        text = page.getOldVersion(oldid=oldid)\n",
    "    else:\n",
    "        text = page.get()\n",
    "    return wtp.parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_laureates = get_nobel_laureates(title='List of Nobel laureates in Physics', oldid=862097595)\n",
    "physics_laureates.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table is extremely messy containing lots of wiki markup so let's clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_laureates_dataframe(table, progress_bar=None):\n",
    "    \"\"\"Cleanup a table of Nobel Laureates from Wikipedia.\n",
    "\n",
    "     Args:\n",
    "        table (pandas.Dataframe): Pandas dataframe containing table\n",
    "            information.\n",
    "        progress_bar (progressbar.ProgressBar): Progress bar.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Dataframe: Dataframe containing the cleaned-up table\n",
    "            information.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # drop uninteresting columns\n",
    "    cleaned_table = table.copy().drop('Image', axis=1)\n",
    "    cleaned_table = cleaned_table.drop('Ref', axis=1)\n",
    "\n",
    "    # cleanup the columns\n",
    "    cleaned_table['Year'] = cleaned_table.Year.apply(\n",
    "        _strip_wikicode).astype('int64')\n",
    "    cleaned_table['Laureate'] = cleaned_table.Laureate.apply(_clean_laureate)\n",
    "    cleaned_table['Rationale'] = cleaned_table.Rationale.apply(_strip_wikicode)\n",
    "    cleaned_table['Country'] = cleaned_table.Country.apply(_strip_wikicode)\n",
    "    cleaned_table['Country'] = cleaned_table.Country.apply(_clean_country)\n",
    "\n",
    "    # NA years the prize was not awarded\n",
    "    cleaned_table.loc[cleaned_table.Rationale.str.contains('Not awarded'),\n",
    "                      ['Laureate', 'Country', 'Rationale']] = np.nan\n",
    "    \n",
    "    # get the redirect title (if any) from a HTTP request\n",
    "    laureates = cleaned_table.Laureate.values.tolist()\n",
    "    redirected_titles = get_redirected_titles(\n",
    "        laureates,\n",
    "        forced_redirects=FORCED_REDIRECTS,\n",
    "        max_workers=10,\n",
    "        progress_bar=progress_bar)\n",
    "    cleaned_table['Laureate'] = cleaned_table.Laureate.apply(\n",
    "        lambda title: redirected_titles[title] if isinstance(title, str) else title)\n",
    "    \n",
    "    return cleaned_table\n",
    "\n",
    "\n",
    "def _clean_laureate(markup):    \n",
    "    # Get the link otherwise return cell as is\n",
    "    links = wtp.parse(markup).wikilinks\n",
    "    if links:\n",
    "        return links[0].target\n",
    "    return markup\n",
    "\n",
    "\n",
    "def _strip_wikicode(markup):\n",
    "    # store the text and target of all wikilinks\n",
    "    wikilinks = {}\n",
    "    parsed = wtp.parse(markup)\n",
    "    for link in parsed.wikilinks:\n",
    "        if link.text:\n",
    "            wikilinks[link.string] = link.text\n",
    "        else:\n",
    "            wikilinks[link.string] = link.target\n",
    "\n",
    "    # replace all wikilinks with the associated text\n",
    "    stripped_string = markup\n",
    "    for link_markup in wikilinks:\n",
    "        stripped_string = stripped_string.replace(\n",
    "            link_markup, wikilinks[link_markup])\n",
    "    return stripped_string\n",
    "\n",
    "\n",
    "def _strip_wikilinks(markup):\n",
    "    return text.replace('[[', '').replace(']]', '')\n",
    "\n",
    "\n",
    "def _clean_country(markup):\n",
    "    countries = []\n",
    "    templates = wtp.parse(markup).templates\n",
    "    for template in templates:\n",
    "        if template.name == 'flag' or template.name == 'flagcountry':\n",
    "            for argument in template.arguments:\n",
    "                try:\n",
    "                    int(argument.value)  # skip if string is a year\n",
    "                except ValueError:\n",
    "                    countries.append(argument.value)\n",
    "\n",
    "    # e.g. \"Not awarded\" case\n",
    "    if not countries:\n",
    "        return markup\n",
    "    return '|'.join(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_URLS = 213\n",
    "physics_laureates = clean_laureates_dataframe(physics_laureates, urls_progress_bar(NUM_URLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 300, 'display.max_colwidth', 500):\n",
    "    display(physics_laureates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better, but let's do a sanity check. The Nobel Prize in Physics:\n",
    "\n",
    "- Has been awarded 111 times between 1901 and 2017\n",
    "- to 207 Nobel Laureates (206 distinct individuals)\n",
    "- *John Bardeen* is the only Nobel Laureate who has been awarded the Nobel Prize twice in 1956 and 1972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(physics_laureates.dropna().Year.unique() == 111))\n",
    "assert(np.array_equal(physics_laureates.Year.unique(), np.array(range(1901, 2018))))\n",
    "assert(len(physics_laureates.dropna().Laureate == 207))\n",
    "assert(len(physics_laureates.loc[physics_laureates.Laureate == 'John Bardeen'] == 2))\n",
    "assert(np.array_equal(physics_laureates.loc[physics_laureates.Laureate == 'John Bardeen'].Year,\n",
    "                      [1956, 1972]))\n",
    "assert(len(physics_laureates.dropna().Laureate.unique() == 206))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks good so let's write the data to a csv file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_laureates.to_csv('../data/raw/nobel-physics-prize-laureates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Nobel Chemistry Laureates\n",
    "\n",
    "Let's use the functions we created above, but this time for the chemistry laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemistry_laureates = get_nobel_laureates(title='List of Nobel laureates in Chemistry', oldid=860639110)\n",
    "chemistry_laureates.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_URLS = 186\n",
    "chemistry_laureates = clean_laureates_dataframe(chemistry_laureates, urls_progress_bar(NUM_URLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 200, 'display.max_colwidth', 500):\n",
    "    display(chemistry_laureates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, but let's do a sanity check. The Nobel Prize in Chemistry:\n",
    "\n",
    "- Has been awarded 109 times between 1901 and 2017\n",
    "- to 178 Nobel Laureates (177 distinct individuals)\n",
    "- Frederick Sanger is the only Nobel Laureate who has been awarded the Nobel Prize in Chemistry twice, in 1958 and 1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(chemistry_laureates.dropna().Year.unique() == 109))\n",
    "assert(np.array_equal(chemistry_laureates.Year.unique(), np.array(range(1901, 2018))))\n",
    "assert(len(chemistry_laureates.dropna().Laureate == 178))\n",
    "assert(len(chemistry_laureates.loc[chemistry_laureates.Laureate == 'Frederick Sanger'] == 2))\n",
    "assert(np.array_equal(chemistry_laureates.loc[chemistry_laureates.Laureate == 'Frederick Sanger'].Year,\n",
    "                      [1958, 1980]))\n",
    "assert(len(chemistry_laureates.dropna().Laureate.unique() == 177))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks good so let's write the data to a csv file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemistry_laureates.to_csv('../data/raw/nobel-chemistry-prize-laureates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up\n",
    "\n",
    "A clean up step is needed:\n",
    "\n",
    "- Unset the environment variable that was set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del os.environ['PYWIKIBOT_NO_USER_CONFIG']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
