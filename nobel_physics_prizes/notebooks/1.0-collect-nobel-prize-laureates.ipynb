{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Nobel Prize Laureates\n",
    "\n",
    "It is essential for this project to know who the *Nobel Laureates in Physics* are. I will scrape a list of [Nobel Laureates in Physics (1901 - 2017)](https://en.wikipedia.org/w/index.php?title=List_of_Nobel_laureates_in_Physics&oldid=862097595) from Wikipedia. *Nobel Laureates in Chemistry* are included in the nomination process for the *Nobel Prize in Physics* and some of them were academic advisors or associated with Physics Nobel Laureates. Therefore, to examine how these relationships possibly affect the awarding of the *Nobel Prize in Physics*, I will also scrape a list of [Nobel Laureates in Chemistry (1901 - 2017)](https://en.wikipedia.org/w/index.php?title=List_of_Nobel_laureates_in_Chemistry&oldid=860639110) from Wikipedia.  You should at least recognize a few of the more famous names on both lists even if you do not recognize them all. You may also be wondering why some famous names in physics are not on the list. OK time to get scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment\n",
    "\n",
    "An initialization step is needed to setup the environment:\n",
    "- An environment variable needs to be set to disable loading of `user-config.py` for *pywikibot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PYWIKIBOT_NO_USER_CONFIG=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywikibot as pwb\n",
    "import wikitextparser as wtp\n",
    "\n",
    "from src.data.url_utils import urls_progress_bar\n",
    "from src.data.wiki_utils import FORCED_REDIRECTS\n",
    "from src.data.wiki_utils import get_redirected_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Nobel Physics Laureates\n",
    "\n",
    "I use a combination of *pywikibot* and *wikitextparser* to scrape the table from the Wikipedia page and create a *pandas* dataframe. As described previously, I use *requests* to send HTTP requests to fetch the pages associated with the Nobel Laureates as some of them are redirected to different URLs. The really tricky part is that the redirects are done via javascript so they are not detected by requests. As a result I use *beautifulsoup* to parse the javascript to find the redirect link.\n",
    "\n",
    "Even after all of this, some of the redirected Wikipedia links are not in sync with the DBpedia links. This means that when I later try to fetch the data from DBpedia, the links resolve the the wrong resource. So I force these redirects manually here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nobel_laureates(code='en', fam='wikipedia',\n",
    "                        title='List of Nobel laureates in Physics',\n",
    "                        oldid=None):\n",
    "    \"\"\"Get a table of Nobel Laureates from Wikipedia.\n",
    "\n",
    "     Args:\n",
    "         code (str): Language code as defined by `pywikibot`.\n",
    "         fam (str): Family name or object as defined by `pywikibot`.\n",
    "         title (str): The title of the Wikipedia page as defined by `pywikibot`.\n",
    "             This is essentially the path name to the url with any underscores\n",
    "             replaced by spaces.\n",
    "             e.g. `https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Physics`\n",
    "             has title `List of Nobel laureates in Physics`.\n",
    "        oldid (int): The revid of the revision of the page desired. \n",
    "\n",
    "    Returns:\n",
    "        pandas.Dataframe: Dataframe containing the table information.\n",
    "\n",
    "    \"\"\"\n",
    "    site = pwb.Site(code=code, fam=fam)\n",
    "    return _get_nobel_laureates(site, title, oldid=oldid)\n",
    "\n",
    "\n",
    "def _get_nobel_laureates(site, title, oldid=None):\n",
    "    code = _get_page_wikicode(site, title, oldid=oldid)\n",
    "    table = code.tables[0].data()\n",
    "    laureates = pd.DataFrame(table[1:], columns=[\n",
    "        'Year', 'Image', 'Laureate', 'Country', 'Rationale', 'Ref'])\n",
    "    return laureates\n",
    "\n",
    "\n",
    "def _get_page_wikicode(site, page_title, oldid=None):\n",
    "    page = pwb.Page(site, page_title)\n",
    "    if oldid:\n",
    "        text = page.getOldVersion(oldid=oldid)\n",
    "    else:\n",
    "        text = page.get()\n",
    "    return wtp.parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_laureates = get_nobel_laureates(\n",
    "    title='List of Nobel laureates in Physics', oldid=862097595)\n",
    "physics_laureates.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table is extremely messy containing lots of wiki markup so let's clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_laureates_dataframe(table, progress_bar=None):\n",
    "    \"\"\"Cleanup a table of Nobel Laureates from Wikipedia.\n",
    "\n",
    "     Args:\n",
    "        table (pandas.Dataframe): Pandas dataframe containing table\n",
    "            information.\n",
    "        progress_bar (progressbar.ProgressBar): Progress bar.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Dataframe: Dataframe containing the cleaned-up table\n",
    "            information.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # drop uninteresting columns\n",
    "    cleaned_table = table.copy().drop('Image', axis=1)\n",
    "    cleaned_table = cleaned_table.drop('Ref', axis=1)\n",
    "\n",
    "    # cleanup the columns\n",
    "    cleaned_table['Year'] = cleaned_table.Year.apply(\n",
    "        _strip_wikicode).astype('int64')\n",
    "    cleaned_table['Laureate'] = cleaned_table.Laureate.apply(_clean_laureate)\n",
    "    cleaned_table['Rationale'] = cleaned_table.Rationale.apply(_strip_wikicode)\n",
    "    cleaned_table['Country'] = cleaned_table.Country.apply(_strip_wikicode)\n",
    "    cleaned_table['Country'] = cleaned_table.Country.apply(_clean_country)\n",
    "\n",
    "    # NA years the prize was not awarded\n",
    "    cleaned_table.loc[cleaned_table.Rationale.str.contains('Not awarded'),\n",
    "                      ['Laureate', 'Country', 'Rationale']] = np.nan\n",
    "    \n",
    "    # get the redirect title (if any) from a HTTP request\n",
    "    laureates = cleaned_table.Laureate.values.tolist()\n",
    "    redirected_titles = get_redirected_titles(\n",
    "        laureates,\n",
    "        forced_redirects=FORCED_REDIRECTS,\n",
    "        max_workers=10,\n",
    "        progress_bar=progress_bar)\n",
    "    cleaned_table['Laureate'] = cleaned_table.Laureate.apply(\n",
    "        lambda title: redirected_titles[title] if isinstance(title, str) else title)\n",
    "    \n",
    "    return cleaned_table\n",
    "\n",
    "\n",
    "def _clean_laureate(markup):    \n",
    "    # Get the link otherwise return cell as is\n",
    "    links = wtp.parse(markup).wikilinks\n",
    "    if links:\n",
    "        return links[0].target\n",
    "    return markup\n",
    "\n",
    "\n",
    "def _strip_wikicode(markup):\n",
    "    # store the text and target of all wikilinks\n",
    "    wikilinks = {}\n",
    "    parsed = wtp.parse(markup)\n",
    "    for link in parsed.wikilinks:\n",
    "        if link.text:\n",
    "            wikilinks[link.string] = link.text\n",
    "        else:\n",
    "            wikilinks[link.string] = link.target\n",
    "\n",
    "    # replace all wikilinks with the associated text\n",
    "    stripped_string = markup\n",
    "    for link_markup in wikilinks:\n",
    "        stripped_string = stripped_string.replace(\n",
    "            link_markup, wikilinks[link_markup])\n",
    "    return stripped_string\n",
    "\n",
    "\n",
    "def _strip_wikilinks(markup):\n",
    "    return text.replace('[[', '').replace(']]', '')\n",
    "\n",
    "\n",
    "def _clean_country(markup):\n",
    "    countries = []\n",
    "    templates = wtp.parse(markup).templates\n",
    "    for template in templates:\n",
    "        if template.name == 'flag' or template.name == 'flagcountry':\n",
    "            for argument in template.arguments:\n",
    "                try:\n",
    "                    int(argument.value)  # skip if string is a year\n",
    "                except ValueError:\n",
    "                    countries.append(argument.value)\n",
    "\n",
    "    # e.g. \"Not awarded\" case\n",
    "    if not countries:\n",
    "        return markup\n",
    "    return '|'.join(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_URLS = 213\n",
    "physics_laureates = clean_laureates_dataframe(physics_laureates, \n",
    "                                              urls_progress_bar(NUM_URLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 300, 'display.max_colwidth', 500):\n",
    "    display(physics_laureates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better, but let's do a sanity check. The *Nobel Prize in Physics*:\n",
    "\n",
    "- Has been awarded 111 times between 1901 and 2017\n",
    "- to 207 Nobel Laureates (206 distinct individuals)\n",
    "- *John Bardeen* is the only Nobel Laureate who has been awarded the Nobel Prize twice in 1956 and 1972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(physics_laureates.dropna().Year.unique() == 111))\n",
    "assert(np.array_equal(physics_laureates.Year.unique(),\n",
    "                      np.array(range(1901, 2018))))\n",
    "assert(len(physics_laureates.dropna().Laureate == 207))\n",
    "assert(len(physics_laureates.loc[\n",
    "    physics_laureates.Laureate == 'John Bardeen'] == 2))\n",
    "assert(np.array_equal(\n",
    "    physics_laureates.loc[\n",
    "        physics_laureates.Laureate == 'John Bardeen'].Year, [1956, 1972]))\n",
    "assert(len(physics_laureates.dropna().Laureate.unique() == 206))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks good so let's write the data to a csv file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_laureates.to_csv('../data/raw/nobel-physics-prize-laureates.csv',\n",
    "                         index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Nobel Chemistry Laureates\n",
    "\n",
    "Let's use the functions we created above, but this time for the chemistry laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemistry_laureates = get_nobel_laureates(\n",
    "    title='List of Nobel laureates in Chemistry', oldid=860639110)\n",
    "chemistry_laureates.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_URLS = 186\n",
    "chemistry_laureates = clean_laureates_dataframe(chemistry_laureates,\n",
    "                                                urls_progress_bar(NUM_URLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 200, 'display.max_colwidth', 500):\n",
    "    display(chemistry_laureates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, but let's do a sanity check. The *Nobel Prize in Chemistry*:\n",
    "\n",
    "- Has been awarded 109 times between 1901 and 2017\n",
    "- to 178 Nobel Laureates (177 distinct individuals)\n",
    "- Frederick Sanger is the only Nobel Laureate who has been awarded the Nobel Prize in Chemistry twice, in 1958 and 1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(chemistry_laureates.dropna().Year.unique() == 109))\n",
    "assert(np.array_equal(chemistry_laureates.Year.unique(),\n",
    "                      np.array(range(1901, 2018))))\n",
    "assert(len(chemistry_laureates.dropna().Laureate == 178))\n",
    "assert(len(chemistry_laureates.loc[\n",
    "    chemistry_laureates.Laureate == 'Frederick Sanger'] == 2))\n",
    "assert(np.array_equal(\n",
    "    chemistry_laureates.loc[\n",
    "        chemistry_laureates.Laureate == 'Frederick Sanger'].Year, [1958, 1980]))\n",
    "assert(len(chemistry_laureates.dropna().Laureate.unique() == 177))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks good so let's write the data to a csv file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemistry_laureates.to_csv('../data/raw/nobel-chemistry-prize-laureates.csv',\n",
    "                           index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up\n",
    "\n",
    "A clean up step is needed:\n",
    "\n",
    "- Unset the environment variable that was set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del os.environ['PYWIKIBOT_NO_USER_CONFIG']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
