{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Features\n",
    "\n",
    "As a recap, the [training data](../data/processed/train-physicists-from-1901.csv) and [test data](../data/processed/test-physicists-from-1901.csv) contain information on physicists who were eligible to receive a Nobel Prize in Physics. That is, they were alive on and after 10 December 1901, the date the prize was first awarded. \n",
    "\n",
    "All of the physicists in the training data are deceased and all the physicists in the test data are alive (up to the last 6-18 months since this is the approximate length of time DBpedia data is behind Wikipedia articles). Since one of the goals of this project is to try to predict the next Physics Nobel Laureate(s). The data was purposely sampled in this way as the aim is to use the training set to build models that predict whether a physicist who is still alive has been awarded or is likely to be awarded the *Nobel Prize in Physics*.\n",
    "\n",
    "It is finally time to use the training and test data, along with the other various pieces of data ([Nobel Physics Laureates](../data/raw/nobel-physics-prize-laureates.csv), [Nobel Chemistry Laureates](../data/raw/nobel-chemistry-prize-laureates.csv), [Places](../data/processed/places.csv) and [Countries](../data/processed/Countries-List.csv)) that I have collected, in order to create features that may help in predicting *Nobel Laureates in Physics*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment\n",
    "\n",
    "An initialization step is needed to setup the environment:\n",
    "- The locale needs to be set for all categories to the userâ€™s default setting (typically specified in the LANG environment variable) to enable correct sorting of words with accents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "    \n",
    "locale.setlocale(locale.LC_ALL, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycountry_convert import country_alpha2_to_country_name\n",
    "from pycountry_convert import country_name_to_country_alpha3\n",
    "from pycountry_convert import country_alpha2_to_continent_code\n",
    "from pycountry_convert import country_alpha3_to_country_alpha2\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from src.data.country_utils import nationality_to_alpha2_code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "\n",
    "First let's read in the training and test data and the list of Nobel Physics laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_physicists = pd.read_csv(\n",
    "    '../data/processed/train-physicists-from-1901.csv')\n",
    "train_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_physicists = pd.read_csv(\n",
    "    '../data/processed/test-physicists-from-1901.csv')\n",
    "test_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_physicists = pd.read_csv(\n",
    "    '../data/raw/nobel-physics-prize-laureates.csv')\n",
    "nobel_physicists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some variants of the name in the training and test data. Since I'll be searching for whether academic advisors, students, spouses, children etc. of a physicist are physics laureates, for convenience it's useful to merge the `name` field into *Nobel Physicists* dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_columns = ['Year', 'Laureate', 'name', 'Country', 'Rationale']\n",
    "nobel_physicists = pd.merge(nobel_physicists,\n",
    "                            train_physicists.append(test_physicists),\n",
    "                            how = 'left', left_on = 'Laureate',\n",
    "                            right_on = 'fullName')[nobel_columns]\n",
    "nobel_physicists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the list of Nobel Chemistry laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_chemists = pd.read_csv(\n",
    "    '../data/raw/nobel-chemistry-prize-laureates.csv')\n",
    "nobel_chemists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I'll be searching for whether academic advisors, students, spouses, children etc. of a physicist are chemistry laureates. So for convenience it's useful to merge the `name` field into *Nobel Chemists* dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_chemists = pd.merge(nobel_chemists, train_physicists.append(test_physicists),\n",
    "                          how = 'left', left_on = 'Laureate',\n",
    "                          right_on = 'fullName')[nobel_columns]\n",
    "nobel_chemists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are essentially physicists who are *Chemistry Nobel Laureates*. Surpringly there are quite a few of them. Of course, as noted previously, *Marie Curie* is the only double laureate in Physics and Chemistry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_chemists[nobel_chemists.name.notna()].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that if there are alternative names of Chemistry Nobel Laureates in the physicists dataframe other than those above, they will *not* be found. However, I do not expect many of these as at one point I got all the redirected URLS for the names and there were very few associated with laureates. In fact you can still see that some of these names are present in the [DBpedia redirects](../data/raw/dbpedia-redirects.csv) (e.g. search for \"Marie_Curie\"). The reason I removed the imputing of these redirects for names when processing the physicist data earlier was that a few of them were plain wrong. For instance, Richard Feynman's children redirect back to him! (e.g. search for \"Carl_Feynman\" and \"Michelle_Feynmann\" in the DBpedia redirects or directly try in your browser http://dbpedia.org/page/Carl_Feynman or http://dbpedia.org/page/Michelle_Feynmann.\n",
    "\n",
    "Another interesting fact about this list is that the only one still alive is *Manfred Eigen*. So I would not expect to see many (if any) physicists in the test set who have Chemistry Nobel Laureate academic advisors, notable students, spouses etc. This is clearly a facet in which the training and test data is very different. Such differences make learning quite difficult.\n",
    "\n",
    "Now, let's read the places and nationalities data into a dataframe. It's important at this point to turn off the default behavior of *pandas* which is to treat the string literal 'NA' as a missing value. In the dataset, 'NA' is both the continent code of North America and the ISO 3166 alpha-2 country code of Namibia. I then have to impute the missing values since *pandas* replaces them with the empty string.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv('../data/processed/places.csv',\n",
    "                     keep_default_na=False)\n",
    "places = places.replace('', np.nan)\n",
    "assert(all(places[\n",
    "    places.countryAlpha3Code == 'USA']['continentCode'].values == 'NA'))\n",
    "places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities = pd.read_csv('../data/processed/Countries-List.csv',\n",
    "                            keep_default_na=False)\n",
    "nationalities = nationalities.replace('', np.nan)\n",
    "assert(nationalities[\n",
    "    nationalities.Name == 'Namibia']['ISO 3166 Code'].values == 'NA')\n",
    "nationalities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, with all the data read in, I can now move on to the bulk of the work, which is creating the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Features\n",
    "\n",
    "It is now time to create the features from the data I have collected. The *features* I am going to create are listed in the table below along with their *type* and *description*. The features can be grouped into three main groups, with the bulk of features falling in the first group, then the second group and so on:\n",
    "\n",
    "1. Features related to *professional and personal relationships* that the physicists have to *physics or chemistry laureates*, *educational institutions*, *work institutions*, *countries* / *continents*.\n",
    "\n",
    "2. Features related to the subfield of focus of the physicist denoting whether s/he is a *experimental physicist*, *theoretical physicist* and / or an *astronomer*.\n",
    "\n",
    "3. Features related to personal characteristics of the physicist, namely, *gender* and *number of years lived*.\n",
    "\n",
    "Remember that in the first group, there are people and institutions from different countries / continents that are directly involved in the [selection and voting process for the Nobel Prize in Physics](https://www.nobelprize.org/nomination/physics/) and therefore have a direct influence on those who become laureates. The second group is connected to subjective biases that may or may not exist concerning the major subfield of research of the physicist. Whilst the third group is connected to subjective biases that may or may not exist concerning the gender and age of a physicist. Although the latter is also related to the invention or discovery \"standing the test of time\".\n",
    "\n",
    "| Feature                                        | Type        | Description                                         |\n",
    "| :---:                                          | :---:       | :---:                                               |\n",
    "| alma_mater                                     | Categorical | List of universities attended                       |\n",
    "| alma_mater_continent_codes                     | Categorical | List of continent codes of universities attended    |\n",
    "| alma_mater_country_alpha_3_codes               | Categorical | List of country codes of universities attended      |\n",
    "| birth_continent_codes                          | Categorical | List of continent codes of birth countries          |\n",
    "| birth_country_alpha_3_codes                    | Categorical | List of country codes of birth countries            |\n",
    "| citizenship_continent_codes                    | Categorical | List of continent codes of coutries of citizenship  |\n",
    "| citizenship_country_alpha_3_codes              | Categorical | List of country codes of citizenship                |\n",
    "| death_continent_codes                          | Categorical | List of continent codes of death countries          |\n",
    "| death_country_alpha_3_codes                    | Categorical | List of country codes of death countries            |\n",
    "| gender                                         | Binary      | Gender of physicist (male / female)                 |\n",
    "| is_astronomer                                  | Binary      | Is the physicist an astronomer? (yes / no)          |\n",
    "| is_experimental_physicist                      | Binary      | Is the physicist an experimental physicist? (yes / no) |\n",
    "| is_theoretical_physicist                       | Binary      | Is the physicist a theoretical physicist? (yes / no) |\n",
    "| ratio_num_alma_mater                           | Ratio       | Ratio of no. of universities attended                       |\n",
    "| ratio_num_alma_mater_continent_codes           | Ratio       | Ratio of no. of continent codes of universities attended     |\n",
    "| ratio_num_alma_mater_country_alpha_3_codes     | Ratio       | Ratio of no. of country codes of universities attended       |\n",
    "| ratio_num_birth_continent_codes                | Ratio       | Ratio of no. of continent codes of birth countries           |\n",
    "| ratio_num_birth_country_alpha_3_codes          | Ratio       | Ratio of no. of birth country codes                          | \n",
    "| ratio_num_chemistry_laureate_academic_advisors | Ratio       | Ratio of no. of chemistry laureate academic advisors         |\n",
    "| ratio_num_chemistry_laureate_children          | Ratio       | Ratio of no. of chemistry laureate children                  |\n",
    "| ratio_num_chemistry_laureate_doctoral_advisors | Ratio       | Ratio of no. of chemistry laureate doctoral advisors         |\n",
    "| ratio_num_chemistry_laureate_doctoral_students | Ratio       | Ratio of no. of chemistry laureate doctoral students         |\n",
    "| ratio_num_chemistry_laureate_influenced        | Ratio       | Ratio of no. of chemistry laureates the physicist influenced |\n",
    "| ratio_num_chemistry_laureate_influenced_by     | Ratio       | Ratio of no. of chemistry laureates the physicist was influenced by | \n",
    "| ratio_num_chemistry_laureate_notable_students  | Ratio       | Ratio of no. of chemistry laureate notable students          |\n",
    "| ratio_num_chemistry_laureate_parents           | Ratio       | Ratio of no. of chemistry laureate parents                   |\n",
    "| ratio_num_chemistry_laureate_spouses           | Ratio       | Ratio of no. of chemistry laureate spouses                   | \n",
    "| ratio_num_citizenship_continent_codes          | Ratio       | Ratio of no. continent codes of countries of citizenship  |\n",
    "| ratio_num_citizenship_country_alpha_3_codes    | Ratio       | Ratio of no. of country codes of citizenship                 |\n",
    "| ratio_num_death_continent_codes                | Ratio       | Ratio of no. of continent codes of death countries           |\n",
    "| ratio_num_death_country_alpha_3_codes          | Ratio       | Ratio of no. of country codes of death countries             |\n",
    "| ratio_num_physics_laureate_academic_advisors   | Ratio       | Ratio of no. of physics laureate academic advisors           |\n",
    "| ratio_num_physics_laureate_children            | Ratio       | Ratio of no. of physics laureate children                    |\n",
    "| ratio_num_physics_laureate_doctoral_advisors   | Ratio       | Ratio of no. of physics laureate doctoral advisors           |\n",
    "| ratio_num_physics_laureate_doctoral_students   | Ratio       | Ratio of no. of physics laureate doctoral students           |\n",
    "| ratio_num_physics_laureate_influenced          | Ratio       | Ratio of no. of physics laureates the physicist influenced   |\n",
    "| ratio_num_physics_laureate_influenced_by       | Ratio       | Ratio of no. of physics laureates the physicist was influenced by |\n",
    "| ratio_num_physics_laureate_notable_students    | Ratio       | Ratio of no. of physics laureate notable students            |\n",
    "| ratio_num_physics_laureate_parents             | Ratio       | Ratio of no. of physics laureate parents                     |\n",
    "| ratio_num_physics_laureate_spouses             | Ratio       | Ratio of no. of physics laureate spouses                     |\n",
    "| ratio_num_residence_continent_codes            | Ratio       | Ratio of no. of continent codes of residence countries       |\n",
    "| ratio_num_residence_country_alpha_3_codes      | Ratio       | Ratio of no. of residence country codes                      |\n",
    "| ratio_num_workplaces                           | Ratio       | Ratio of no. of workplaces                                   |\n",
    "| ratio_num_workplaces_continent_codes           | Ratio       | Ratio of no. of continent codes of countries of workplaces   |\n",
    "| ratio_num_workplaces_country_alpha_3_codes     | Ratio       | Ratio of no. of country codes of countries worked in         |\n",
    "| ratio_num_years_lived                          | Ratio       | Ratio of no. of years lived              |\n",
    "| residence_continent_codes                      | Categorical | List of continent codes of countries of residence   |\n",
    "| residence_country_alpha_3_codes                | Categorical | List of country codes of countries of residence     |\n",
    "| workplaces                                     | Categorical | List of workplaces                                  |\n",
    "| workplaces_continent_codes                     | Categorical | List of continent codes of countries worked in      |\n",
    "| workplaces_country_alpha_3_codes               | Categorical | List of country codes of countries worked in        |\n",
    "\n",
    "Some comments are warranted with regards to the types of the feature variables also. As you can see we have three types of variables:\n",
    "\n",
    "1. **Ratio** variables of a *continuous*, *quantitative* nature.\n",
    "\n",
    "2. **Categorical** variables of a qualitative nature.\n",
    "\n",
    "3. **Binary** (**dichotomous**) variables of a categorical nature.\n",
    "\n",
    "Every ratio variable is to be calculated by dividing the *individual physicist count* by the *mean count in the training set* for a particular feature. So a ratio represents how much more or less than the average value a particular physicist is. Values above one indicate that the physicist is above the average whilst values below one indicate that s/he is below the average for a specific feature.  For instance, if `ratio_num_alma_mater_country_alpha_3_codes` = 2.5 for a particular physicist, it means that the physicist has attended two and a half times more universities than the typical physicist in the training set.  \n",
    "\n",
    "The categorical variables are all lists of varying lengths of *places* and therefore are not in the appropriate form for machine learning. Once I create them I will actually *one-hot-encode* them into binary variables and discard the lists. You may ask why the one-hot-encoding is done with categorical yes / no values rather than 0 / 1 values? It is because the algorithms I will be processing the data with would treat 0 / 1 values as quantitive in nature which is clearly not what is desired. Essentially I will be left with two variable types, just binary variables and ratio variables. OK time to go ahead and create the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(physicists, nobel_physicists, nobel_chemists,\n",
    "                   places, nationalities):\n",
    "    \"\"\"Build features for the physicists.\n",
    "\n",
    "    Args:\n",
    "        physicists (pandas.DataFrame): Physicists dataframe.\n",
    "        nobel_physicists (pandas.DataFrame): Nobel Physics\n",
    "            Laureate dataframe.\n",
    "        nobel_chemists (pandas.DataFrame): Nobel Chemistry\n",
    "            Laureate dataframe.\n",
    "        places (pandas.DataFrame): Places dataframe.\n",
    "        nationality (pandas.DataFrame): Nationalies dataframe.\n",
    "            \n",
    "    Returns:\n",
    "        pandas.DataFrame: Features dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = physicists.copy()[['fullName', 'name', 'gender']].rename(\n",
    "        mapper={'fullName': 'full_name'}, axis='columns')\n",
    "    features['num_years_lived'] = _build_num_years_lived(\n",
    "        physicists.birthDate, physicists.deathDate)\n",
    "    \n",
    "    _build_physics_subfield_features(features, physicists)\n",
    "    _build_num_laureates_features(features, physicists,\n",
    "                                  nobel_physicists, nobel_chemists)\n",
    "    \n",
    "    _build_citizenship_features(features, physicists, nationalities)\n",
    "    \n",
    "    _build_places_features(features, physicists, places)\n",
    "    \n",
    "    features = features.drop('name', axis='columns')\n",
    "    return features\n",
    "\n",
    "\n",
    "def _build_physics_subfield_features(features, physicists):\n",
    "    features_to_build = {\n",
    "        'is_theoretical_physicist': {'categories': 'Theoretical physicists',\n",
    "                                     'others': 'theoretical physic'},\n",
    "        'is_experimental_physicist': {'categories': 'Experimental physicists',\n",
    "                                      'others': 'experimental physic'},\n",
    "        'is_astronomer': {'categories': 'astronomers',\n",
    "                          'others': 'astronom'}\n",
    "    }\n",
    "    \n",
    "    for feature, search_terms in features_to_build.items():\n",
    "        features[feature] = _build_physics_subfield(\n",
    "            physicists.categories, physicists.field, physicists.description,\n",
    "            physicists.comment, search_terms=search_terms)\n",
    "    \n",
    "\n",
    "\n",
    "def _build_num_laureates_features(features, physicists, nobel_physicists,\n",
    "                                  nobel_chemists):\n",
    "    features_to_build = {\n",
    "        'laureate_academic_advisors': 'academicAdvisor',\n",
    "        'laureate_doctoral_advisors': 'doctoralAdvisor',\n",
    "        'laureate_doctoral_students': 'doctoralStudent',\n",
    "        'laureate_notable_students': 'notableStudent',\n",
    "        'laureate_children': 'child',\n",
    "        'laureate_parents': 'parent',\n",
    "        'laureate_spouses': 'spouse',\n",
    "        'laureate_influenced': 'influenced',\n",
    "        'laureate_influenced_by': 'influencedBy'\n",
    "    }\n",
    "    \n",
    "    for feature, relation in features_to_build.items():\n",
    "        features['num_physics_' + feature] = _build_num_laureates(\n",
    "            physicists[relation], nobel_physicists.Laureate, nobel_physicists.name)\n",
    "        features['num_chemistry_' + feature] = _build_num_laureates(\n",
    "            physicists[relation], nobel_chemists.Laureate, nobel_chemists.name)\n",
    "\n",
    "\n",
    "    \n",
    "def _build_places_features(features, physicists, places):\n",
    "    features_to_build = {\n",
    "        'birth_country_alpha_3_codes': 'birthPlace',\n",
    "        'birth_continent_codes': 'birthPlace',\n",
    "        'death_country_alpha_3_codes': 'deathPlace',\n",
    "        'death_continent_codes': 'deathPlace',\n",
    "        'residence_country_alpha_3_codes': 'residence',\n",
    "        'residence_continent_codes': 'residence',\n",
    "        'alma_mater': 'almaMater',\n",
    "        'alma_mater_country_alpha_3_codes': 'almaMater',\n",
    "        'alma_mater_continent_codes': 'almaMater',\n",
    "        'workplaces': 'workplaces',\n",
    "        'workplaces_country_alpha_3_codes': 'workplaces',\n",
    "        'workplaces_continent_codes': 'workplaces'\n",
    "    }\n",
    "    \n",
    "    for feature, place in features_to_build.items():\n",
    "        code = 'countryAlpha3Code'\n",
    "        if 'continent' in feature:\n",
    "            code = 'continentCode'\n",
    "            \n",
    "        if feature in ['alma_mater', 'workplaces']:\n",
    "            features[feature] = physicists[place].apply(\n",
    "                _get_alma_mater_or_workplaces)           \n",
    "        else:\n",
    "            features[feature] = _build_places_codes(\n",
    "                physicists[place], places.fullName, places[code])\n",
    "        features['num_' + feature] = features[feature].apply(len)\n",
    "\n",
    "\n",
    "    \n",
    "def _build_citizenship_features(features, physicists, nationalities):\n",
    "    citizenship = physicists.citizenship.apply(\n",
    "        _get_citizenship_codes, args=(nationalities,))\n",
    "    nationality = physicists.nationality.apply(\n",
    "        _get_citizenship_codes, args=(nationalities,))\n",
    "    citizenship_description = physicists.description.apply(\n",
    "        _get_citizenship_codes, args=(nationalities,))\n",
    "    features['citizenship_country_alpha_3_codes'] = (\n",
    "        (citizenship + nationality + citizenship_description).apply(\n",
    "            lambda ctz: list(sorted(set(ctz)))))\n",
    "    features['num_citizenship_country_alpha_3_codes'] = (\n",
    "        features.citizenship_country_alpha_3_codes.apply(len))\n",
    "    features['citizenship_continent_codes'] = (\n",
    "        features.citizenship_country_alpha_3_codes.apply(\n",
    "            lambda al3: list(sorted({country_alpha2_to_continent_code(\n",
    "                country_alpha3_to_country_alpha2(cd)) for cd in al3}))))\n",
    "    features['num_citizenship_continent_codes'] = (\n",
    "        features.citizenship_continent_codes.apply(len))\n",
    "\n",
    "\n",
    "def _build_num_years_lived(birth_date, death_date):\n",
    "    death_date_no_nan = death_date.apply(_date_no_nan)\n",
    "    birth_date_no_nan = birth_date.apply(_date_no_nan)\n",
    "    years_lived = ((death_date_no_nan - birth_date_no_nan) /\n",
    "                   pd.to_timedelta(1, 'Y'))\n",
    "    return years_lived.astype('int64')\n",
    "\n",
    "\n",
    "def _build_physics_subfield(categories, field, description, comment, search_terms):\n",
    "    cat_theoretical_physicist = categories.apply(\n",
    "        lambda cat: search_terms['categories'] in cat)\n",
    "    field_theoretical_physicist = field.apply(\n",
    "        lambda fld: search_terms['others'] in fld.lower() if isinstance(fld, str)\n",
    "        else False)\n",
    "    desc_theoretical_physicist = description.apply(\n",
    "        lambda desc: search_terms['others'] in desc.lower() if isinstance(desc, str)\n",
    "        else False)\n",
    "    comm_theoretical_physicist = description.apply(\n",
    "        lambda comm: search_terms['others'] in comm.lower() if isinstance(comm, str)\n",
    "        else False)\n",
    "    subfield = (cat_theoretical_physicist |\n",
    "                field_theoretical_physicist |\n",
    "                desc_theoretical_physicist |\n",
    "                comm_theoretical_physicist)\n",
    "    subfield = subfield.apply(lambda val: 'yes' if val == True else 'no')\n",
    "    return subfield\n",
    "\n",
    "\n",
    "def _build_num_laureates(series, laureates, names):\n",
    "    laureate_names = series.apply(_get_nobel_laureates,\n",
    "                                  args=(laureates, names))\n",
    "    return laureate_names.apply(len)\n",
    "\n",
    "\n",
    "def _build_places_codes(places_in_physicists, full_name_in_places, places_codes):\n",
    "    codes = places_in_physicists.apply(_get_places_codes,\n",
    "                                       args=(full_name_in_places, places_codes))\n",
    "    return codes\n",
    "\n",
    "\n",
    "def _get_alma_mater_or_workplaces(cell):\n",
    "    if isinstance(cell, float):\n",
    "        return list()\n",
    "    \n",
    "    places = set()\n",
    "    places_in_cell = cell.split('|')\n",
    "    for place_in_cell in places_in_cell:\n",
    "        # group colleges of University of Oxford and University of Cambridge\n",
    "        # with their respective parent university\n",
    "        if place_in_cell.endswith(', Cambridge'):\n",
    "            places.add('University of Cambridge')\n",
    "        elif place_in_cell.endswith(', Oxford'):\n",
    "            places.add('University of Oxford')\n",
    "        else:\n",
    "            places.add(place_in_cell)\n",
    "    \n",
    "    places = list(places)\n",
    "    places.sort(key=locale.strxfrm)\n",
    "    return places\n",
    "\n",
    "\n",
    "def _get_citizenship_codes(series, nationalities):\n",
    "    alpha_2_codes = nationality_to_alpha2_code(series, nationalities)\n",
    "    if isinstance(alpha_2_codes, float):\n",
    "        return list()\n",
    "    alpha_2_codes = alpha_2_codes.split('|')\n",
    "    alpha_3_codes = [country_name_to_country_alpha3(\n",
    "        country_alpha2_to_country_name(alpha_2_code))\n",
    "                     for alpha_2_code in alpha_2_codes]\n",
    "    return alpha_3_codes\n",
    "\n",
    "\n",
    "def _get_nobel_laureates(cell, laureates, names):\n",
    "    laureates_in_cell = set()\n",
    "    \n",
    "    if isinstance(cell, str):\n",
    "        # assume the same name if only differs by a hyphen\n",
    "        # or whitespace at front or end of string\n",
    "        values = cell.strip().replace('-', ' ').split('|')\n",
    "        for value in values:\n",
    "            if value in laureates.values:\n",
    "                laureates_in_cell.add(value)\n",
    "            if names.str.contains(value, regex=False).sum() > 0:\n",
    "                laureates_in_cell.add(value)\n",
    "                    \n",
    "    laureates_in_cell = list(laureates_in_cell)\n",
    "    return laureates_in_cell\n",
    "\n",
    "    \n",
    "def _get_places_codes(cell, full_name_in_places, places_codes):\n",
    "    codes = set()\n",
    "\n",
    "    if isinstance(cell, str):\n",
    "        places = cell.split('|')\n",
    "        for place in places:\n",
    "            code_indices = full_name_in_places[\n",
    "                full_name_in_places == place].index\n",
    "            assert(len(code_indices) <= 1)\n",
    "            if len(code_indices) != 1:\n",
    "                continue\n",
    "            code_index = code_indices[0]\n",
    "            codes_text = places_codes[code_index]\n",
    "            if isinstance(codes_text, float):\n",
    "                continue\n",
    "            codes_in_cell = codes_text.split('|')\n",
    "            for code_in_cell in codes_in_cell:\n",
    "                if code_in_cell:\n",
    "                    codes.add(code_in_cell)\n",
    "\n",
    "    codes = list(codes)\n",
    "    codes.sort()\n",
    "    return codes\n",
    "    \n",
    "\n",
    "def _date_no_nan(date):\n",
    "    if isinstance(date, str):\n",
    "        return datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    return datetime(2018, 10, 24).date()  # fix the date for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = build_features(\n",
    "    train_physicists, nobel_physicists, nobel_chemists, places, nationalities)\n",
    "assert((len(train_features) == len(train_physicists)))\n",
    "assert(len(train_features.columns) == 52)\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = build_features(\n",
    "    test_physicists, nobel_physicists, nobel_chemists, places, nationalities)\n",
    "assert((len(test_features) == len(test_physicists)))\n",
    "assert(test_features.columns.tolist() == train_features.columns.tolist())\n",
    "test_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I one-hot encode the list features. Due to one-hot encoding there are less features in the test set than in the training set. This is because there are differing country codes, workplaces, educational institutions, etc. The majority of the differences are due to the way that the data was sampled. For instance, the `died_in_[country_code]` features cannot possibly appear in the test set features since these\n",
    "physicists are still alive. The rest of the few differences are due variability in the data.\n",
    "\n",
    "Since any machine models I build will be evaluated on the test set, the tempting thing to do is to reduce the features to the common set of features between the training and test sets. However, this would clearly be *data snooping* (cheating) since the test set is meant to be unseen data. The other issue is if some of the features in the training set are thrown away and new examples come along with those exact features, the model would not be able to leverage this information. So the only logical thing to do is to ensure that the test set features are identical to the training set features. I do this by \"padding\" the extra features in the test set with all \"no\" values. Let's go ahead and do this now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_list_features(features, train_features=None,\n",
    "                           presence_threshold=0.0):\n",
    "    \"\"\"Binarize list features.\n",
    "    \n",
    "    One-hot encode the list categorical features in the\n",
    "    features dataframe.\n",
    "\n",
    "    Args:\n",
    "        features (pandas.DataFrame): Features dataframe.\n",
    "        train_features (pandas.DataFrame): Training features\n",
    "            dataframe. Pass this parameter when building features\n",
    "            for a test set so that that identical features are\n",
    "            created for the test set.\n",
    "        presence_threshold (float): For each category in a \n",
    "            categorical list feature, the fraction of\n",
    "            physicists for which the category is present will\n",
    "            be calculated. If the fraction is below this\n",
    "            threshold it will grouped into the \"other\"\n",
    "            category (represented by one or more \"*'s'\" in its\n",
    "            name). This is intended for \"bucketing\" rare\n",
    "            values to keep the dimensionality of the feature\n",
    "            space down and reduce chances of overfitting. Set\n",
    "            this value to zero to prevent any grouping of\n",
    "            values. Note that this value will be ignored when\n",
    "            `train_features` is not None.\n",
    "            \n",
    "    Returns:\n",
    "        pandas.DataFrame: Features dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # union of places and citizenship (without the counts)\n",
    "    series_to_binarize = {\n",
    "        'birth_country_alpha_3_codes': 'born_in_',\n",
    "        'birth_continent_codes': 'born_in_',\n",
    "        'death_country_alpha_3_codes': 'died_in_',\n",
    "        'death_continent_codes': 'died_in_',\n",
    "        'residence_country_alpha_3_codes': 'lived_in_',\n",
    "        'residence_continent_codes': 'lived_in_',\n",
    "        'alma_mater': 'alumnus_of_',\n",
    "        'alma_mater_country_alpha_3_codes': 'alumnus_in_',\n",
    "        'alma_mater_continent_codes': 'alumnus_in_',\n",
    "        'workplaces': 'worked_at_',\n",
    "        'workplaces_country_alpha_3_codes': 'worked_in_',\n",
    "        'workplaces_continent_codes': 'worked_in_',\n",
    "        'citizenship_country_alpha_3_codes': 'citizen_of_',\n",
    "        'citizenship_continent_codes': 'citizen_in_'\n",
    "    }\n",
    "        \n",
    "    for series, prefix in series_to_binarize.items():\n",
    "        binarized = _binarize_list_feature(features[series], prefix,\n",
    "                                           train_features, presence_threshold)\n",
    "        features = features.drop(series, axis='columns').join(binarized)\n",
    "        \n",
    "    # add extra features in test set to sync with training set\n",
    "    if train_features is not None:\n",
    "        cols_to_add = set(train_features.columns) - set(features.columns)\n",
    "        shape=(len(features), len(cols_to_add))\n",
    "        features_to_pad = pd.DataFrame(\n",
    "            np.full(shape, 'no'), index=features.index, columns=cols_to_add)\n",
    "        features = features.join(features_to_pad)\n",
    "    return features\n",
    "    \n",
    "    \n",
    "def _binarize_list_feature(series, prefix, train_features=None,\n",
    "                           presence_threshold=0.0):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binarized = pd.DataFrame(\n",
    "        mlb.fit_transform(series),\n",
    "        columns=[prefix + class_.replace(' ', '_') for class_ in mlb.classes_],\n",
    "        index=series.index)\n",
    "    \n",
    "    if not (presence_threshold <= 0.0) or train_features is not None:\n",
    "        if train_features is not None:\n",
    "            cols_to_group = [col for col in binarized.columns if col not in\n",
    "                             train_features.columns]\n",
    "        else:\n",
    "            cols_to_group = binarized.mean() < presence_threshold\n",
    "            cols_to_group = cols_to_group[cols_to_group.values].index.tolist()\n",
    "            \n",
    "        # look for at least one '1' value in the row for a physicist\n",
    "        if cols_to_group:\n",
    "            other_col = binarized[cols_to_group].applymap(\n",
    "                lambda val: True if val == 1 else False).any(axis='columns')\n",
    "            other_col.name = _series_name(series.name, prefix)\n",
    "            binarized = binarized.drop(cols_to_group, axis='columns').join(other_col)\n",
    "\n",
    "    binarized = binarized.applymap(lambda val: 'yes' if val == 1 else 'no')\n",
    "    return binarized\n",
    "\n",
    "\n",
    "def _series_name(name, prefix):\n",
    "    if name.endswith('alpha_3_codes'):\n",
    "        other_name = '***'\n",
    "    elif name.endswith('continent_codes'):\n",
    "        other_name = '**'\n",
    "    else:\n",
    "        other_name = '*'\n",
    "    return prefix + other_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_threshold = 0.01\n",
    "train_features = binarize_list_features(\n",
    "    train_features, presence_threshold=presence_threshold)\n",
    "assert((len(train_features) == len(train_physicists)))\n",
    "assert(len(train_features.columns) == 187)\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = binarize_list_features(test_features,\n",
    "                                       train_features=train_features)\n",
    "assert((len(test_features) == len(test_physicists)))\n",
    "assert(sorted(test_features.columns.tolist()) == sorted(\n",
    "    train_features.columns.tolist()))\n",
    "test_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I convert the count features to ratio features by diving the cell values by the mean value of the feature. I also drop any features with zero counts in all the columns since they are uninformative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_counts_to_ratios(features, train_features=None):\n",
    "    \"\"\"Convert count features to ratios.\n",
    "    \n",
    "    Converts all counts features in the `features` dataframe to\n",
    "    ratios by dividing cell values by the mean value of the feature.\n",
    "\n",
    "    Args:\n",
    "        features (pandas.DataFrame): Features dataframe.\n",
    "        train_features (pandas.DataFrame): Training features\n",
    "            dataframe. Pass this parameter when building features\n",
    "            for a test set so that the ratios can be created\n",
    "            from the test set data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Features dataframe with counts replaced by ratios.\n",
    "    \"\"\"\n",
    "    \n",
    "    numerator = features.select_dtypes('int64') \n",
    "    if train_features is None:\n",
    "        # drop columns in training features where the counts are all zero\n",
    "        numerator = numerator.loc[:, (numerator != 0).any(axis='rows')]\n",
    "        denominator = numerator.mean()\n",
    "    else:\n",
    "        non_zero_cols = train_features.select_dtypes('int64')\n",
    "        non_zero_cols = non_zero_cols.loc[\n",
    "            :, (non_zero_cols != 0).any(axis='rows')].columns\n",
    "        numerator = numerator[non_zero_cols]\n",
    "        denominator = train_features.select_dtypes('int64')[\n",
    "            non_zero_cols].mean()\n",
    "\n",
    "    features_with_ratios = features.drop(\n",
    "        features.select_dtypes('int64'), axis='columns')\n",
    "    ratio = numerator / denominator\n",
    "    ratio.columns = ['ratio_' + col_name for col_name in ratio.columns]\n",
    "    features_with_ratios = features_with_ratios.join(ratio)\n",
    "\n",
    "    return features_with_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = convert_counts_to_ratios(test_features,\n",
    "                                         train_features=train_features)\n",
    "assert((len(test_features) == len(test_physicists)))\n",
    "assert(len(test_features.columns) == 184)\n",
    "assert(test_features.select_dtypes('int64').empty)\n",
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = convert_counts_to_ratios(train_features)\n",
    "assert((len(train_features) == len(train_physicists)))\n",
    "assert(sorted(train_features.columns.tolist()) == sorted(\n",
    "    test_features.columns.tolist()))\n",
    "assert(train_features.select_dtypes('int64').empty)\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one-hot encoding has increased the dimensionality of the problem. There are now 183 features (excluding the `full_name`) for 540 observations in the training set and 387 observations in the test set. A model that is fit to such data could be prone to overfitting and a dimensionality reduction on this data may be warranted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting the Data\n",
    "\n",
    "Now I have the training and test features dataframes I'll persist them for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.reindex(\n",
    "    sorted(train_features.columns), axis='columns')\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_features.reindex(\n",
    "    sorted(test_features.columns), axis='columns')\n",
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv('../data/processed/train-features.csv', index=False)\n",
    "test_features.to_csv('../data/processed/test-features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
