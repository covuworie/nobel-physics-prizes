{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Features\n",
    "\n",
    "As a recap, the [training data](../data/processed/train-physicists-from-1901.csv) and [test data](../data/processed/test-physicists-from-1901.csv) contain information on physicists who were eligible to receive a Nobel Prize in Physics. That is, they were alive on and after 10 December 1901, the date the prize was first awarded. \n",
    "\n",
    "All of the physicists in the training data are deceased and all the physicists in the test data are alive (up to the last 6-18 months since this is the approximate length of time DBpedia data is behind Wikipedia articles). Since one of the goals of this project is to try to predict the next Physics Nobel Laureate(s). The data was purposely sampled in this way as the aim is to use the training set to build models that predict whether a physicist who is still alive has been awarded or is likely to be awarded the *Nobel Prize in Physics*.\n",
    "\n",
    "It is finally time to use the training and test data, along with the other various pieces of data ([Nobel Physics Laureates](../data/raw/nobel-physics-prize-laureates.csv), [Nobel Chemistry Laureates](../data/raw/nobel-chemistry-prize-laureates.csv), [Places](../data/processed/places.csv) and [Countries](../data/processed/Countries-List.csv)) that I have collected, in order to create features that may help in predicting *Nobel Laureates in Physics*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment\n",
    "\n",
    "An initialization step is needed to setup the environment:\n",
    "- The locale needs to be set for all categories to the userâ€™s default setting (typically specified in the LANG environment variable) to enable correct sorting of words with accents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "    \n",
    "locale.setlocale(locale.LC_ALL, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycountry_convert import country_alpha2_to_country_name\n",
    "from pycountry_convert import country_name_to_country_alpha3\n",
    "from pycountry_convert import country_alpha2_to_continent_code\n",
    "from pycountry_convert import country_alpha3_to_country_alpha2\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from src.data.country_utils import nationality_to_alpha2_code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "\n",
    "First let's read in the training and test data and the list of Nobel Physics laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_physicists = pd.read_csv(\n",
    "    '../data/processed/train-physicists-from-1901.csv')\n",
    "train_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_physicists = pd.read_csv(\n",
    "    '../data/processed/test-physicists-from-1901.csv')\n",
    "test_physicists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_physicists = pd.read_csv(\n",
    "    '../data/raw/nobel-physics-prize-laureates.csv')\n",
    "nobel_physicists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some variants of the name in the training and test data. Since I'll be searching for whether academic advisors, students, spouses, children etc. of a physicist are physics laureates, for convenience it's useful to merge the `name` field into *Nobel Physicists* dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_columns = ['Year', 'Laureate', 'name', 'Country', 'Rationale']\n",
    "nobel_physicists = pd.merge(nobel_physicists,\n",
    "                            train_physicists.append(test_physicists),\n",
    "                            how = 'left', left_on = 'Laureate',\n",
    "                            right_on = 'fullName')[nobel_columns]\n",
    "nobel_physicists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the list of Nobel Chemistry laureates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_chemists = pd.read_csv(\n",
    "    '../data/raw/nobel-chemistry-prize-laureates.csv')\n",
    "nobel_chemists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I'll be searching for whether academic advisors, students, spouses, children etc. of a physicist are chemistry laureates. So for convenience it's useful to merge the `name` field into *Nobel Chemists* dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_chemists = pd.merge(nobel_chemists, train_physicists.append(test_physicists),\n",
    "                          how = 'left', left_on = 'Laureate',\n",
    "                          right_on = 'fullName')[nobel_columns]\n",
    "nobel_chemists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are essentially physicists who are *Chemistry Nobel Laureates*. Surpringly there are quite a few of them. Of course, as noted previously, *Marie Curie* is the only double laureate in Physics and Chemistry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_chemists[nobel_chemists.name.notna()].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that if there are alternative names of Chemistry Nobel Laureates in the physicists dataframe other than those above, they will *not* be found. However, I do not expect many of these as at one point I got all the redirected URLS for the names and there were very few associated with laureates. In fact you can still see that some of these names are present in the [DBpedia redirects](../data/raw/dbpedia-redirects.csv) (e.g. search for \"Marie_Curie\"). The reason I removed the imputing of these redirects for names when processing the physicist data earlier was that a few of them were plain wrong. For instance, Richard Feynman's children redirect back to him! (e.g. search for \"Carl_Feynman\" and \"Michelle_Feynmann\" in the DBpedia redirects or directly try in your browser http://dbpedia.org/page/Carl_Feynman or http://dbpedia.org/page/Michelle_Feynmann.\n",
    "\n",
    "Now, let's read the places and nationalities data into a dataframe. It's important at this point to turn off the default behavior of *pandas* which is to treat the string literal 'NA' as a missing value. In the dataset, 'NA' is both the continent code of North America and the ISO 3166 alpha-2 country code of Namibia. I then have to impute the missing values since *pandas* replaces them with the empty string.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv('../data/processed/places.csv',\n",
    "                     keep_default_na=False)\n",
    "places = places.replace('', np.nan)\n",
    "assert(all(places[\n",
    "    places.countryAlpha3Code == 'USA']['continentCode'].values == 'NA'))\n",
    "places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities = pd.read_csv('../data/processed/Countries-List.csv',\n",
    "                            keep_default_na=False)\n",
    "nationalities = nationalities.replace('', np.nan)\n",
    "assert(nationalities[\n",
    "    nationalities.Name == 'Namibia']['ISO 3166 Code'].values == 'NA')\n",
    "nationalities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, with all the data read in, I can now move on to the bulk of the work, which is creating the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Features\n",
    "\n",
    "It is now time to create the features from the data I have collected. The *features* I am going to create are listed in the table below along with their *type* and *description*. The features can be grouped into three main groups, with the bulk of features falling in the first group, then the second group and so on:\n",
    "\n",
    "1. Features related to *professional and personal relationships* that the physicists have to *physics or chemistry laureates*, *educational institutions*, *work institutions*, *countries* / *continents*.\n",
    "\n",
    "2. Features related to the subfield of focus of the physicist denoting whether s/he is a *experimental physicist*, *theoretical physicist* and / or an *astronomer*.\n",
    "\n",
    "3. Features related to personal characteristics of the physicist, namely, *gender* and *number of years lived*.\n",
    "\n",
    "Remember that in the first group, there are people and institutions from different countries / continents that are directly involved in the [selection and voting process for the Nobel Prize in Physics](https://www.nobelprize.org/nomination/physics/) and therefore have a direct influence on those who become laureates. The second group is connected to subjective biases that may or may not exist concerning the major subfield of research of the physicist. Whilst the third group is connected to subjective biases that may or may not exist concerning the gender and age of a physicist. Although the latter is also related to the invention or discovery \"standing the test of time\".\n",
    "\n",
    "| Feature                                  | Type        | Description                                         |\n",
    "| :---:                                    | :---:       | :---:                                               |\n",
    "| alma_mater                               | Categorical | List of universities attended                       |\n",
    "| alma_mater_continent_codes               | Categorical | List of continent codes of universities attended    |\n",
    "| alma_mater_country_alpha_3_codes         | Categorical | List of country codes of universities attended      |\n",
    "| birth_continent_codes                    | Categorical | List of continent codes of birth countries          |\n",
    "| birth_country_alpha_3_codes              | Categorical | List of country codes of birth countries            |\n",
    "| citizenship_continent_codes              | Categorical | List of continent codes of coutries of citizenship  |\n",
    "| citizenship_country_alpha_3_codes        | Categorical | List of country codes of citizenship                |\n",
    "| death_continent_codes                    | Categorical | List of continent codes of death countries          |\n",
    "| death_country_alpha_3_codes              | Categorical | List of country codes of death countries            |\n",
    "| gender                                   | Binary      | Gender of physicist (male / female)                 |\n",
    "| is_astronomer                            | Binary      | Is the physicist an astronomer? (yes / no)          |\n",
    "| is_experimental_physicist                | Binary      | Is the physicist an experimental physicist? (yes / no) |\n",
    "| is_theoretical_physicist                 | Binary      | Is the physicist a theoretical physicist? (yes / no) |\n",
    "| num_alma_mater                           | Count       | No. of universities attended                        |\n",
    "| num_alma_mater_continent_codes           | Count       | No. of continent codes of universities attended     |\n",
    "| num_alma_mater_country_alpha_3_codes     | Count       | No. of country codes of universities attended       |\n",
    "| num_birth_continent_codes                | Count       | No. of continent codes of birth countries           |\n",
    "| num_birth_country_alpha_3_codes          | Count       | No. of birth country codes                          | \n",
    "| num_chemistry_laureate_academic_advisors | Count       | No. of chemistry laureate academic advisors         |\n",
    "| num_chemistry_laureate_children          | Count       | No. of chemistry laureate children                  |\n",
    "| num_chemistry_laureate_doctoral_advisors | Count       | No. of chemistry laureate doctoral advisors         |\n",
    "| num_chemistry_laureate_doctoral_students | Count       | No. of chemistry laureate doctoral students         |\n",
    "| num_chemistry_laureate_influenced        | Count       | No. of chemistry laureates the physicist influenced |\n",
    "| num_chemistry_laureate_influenced_by     | Count       | No. of chemistry laureates the physicist was influenced by | \n",
    "| num_chemistry_laureate_notable_students  | Count       | No. of chemistry laureate notable students          |\n",
    "| num_chemistry_laureate_parents           | Count       | No. of chemistry laureate parents                   |\n",
    "| num_chemistry_laureate_spouses           | Count       | No. of chemistry laureate spouses                   | \n",
    "| num_citizenship_continent_codes          | Count       | No. of continent codes of countries of citizenship  |\n",
    "| num_citizenship_country_alpha_3_codes    | Count       | No. of country codes of citizenship                 |\n",
    "| num_death_continent_codes                | Count       | No. of continent codes of death countries           |\n",
    "| num_death_country_alpha_3_codes          | Count       | No. of country codes of death countries             |\n",
    "| num_physics_laureate_academic_advisors   | Count       | No. of physics laureate academic advisors           |\n",
    "| num_physics_laureate_children            | Count       | No. of physics laureate children                    |\n",
    "| num_physics_laureate_doctoral_advisors   | Count       | No. of physics laureate doctoral advisors           |\n",
    "| num_physics_laureate_doctoral_students   | Count       | No. of physics laureate doctoral students           |\n",
    "| num_physics_laureate_influenced          | Count       | No. of physics laureates the physicist influenced   |\n",
    "| num_physics_laureate_influenced_by       | Count       | No. of physics laureates the physicist was influenced by |\n",
    "| num_physics_laureate_notable_students    | Count       | No. of physics laureate notable students            |\n",
    "| num_physics_laureate_parents             | Count       | No. of physics laureate parents                     |\n",
    "| num_physics_laureate_spouses             | Count       | No. of physics laureate spouses                     |\n",
    "| num_residence_continent_codes            | Count       | No. of continent codes of residence countries       |\n",
    "| num_residence_country_alpha_3_codes      | Count       | No. of residence country codes                      |\n",
    "| num_workplaces                           | Count       | No. of workplaces                                   |\n",
    "| num_workplaces_continent_codes           | Count       | No. of continent codes of countries of workplaces   |\n",
    "| num_workplaces_country_alpha_3_codes     | Count       | No. of country codes of countries worked in         |\n",
    "| num_years_lived                          | Count       | No. of years lived (equals age or age of death)     |\n",
    "| residence_continent_codes                | Categorical | List of continent codes of countries of residence   |\n",
    "| residence_country_alpha_3_codes          | Categorical | List of country codes of countries of residence     |\n",
    "| workplaces                               | Categorical | List of workplaces                                  |\n",
    "| workplaces_continent_codes               | Categorical | List of continent codes of countries worked in      |\n",
    "| workplaces_country_alpha_3_codes         | Categorical | List of country codes of countries worked in        |\n",
    "\n",
    "Some comments are warranted with regards to the types of the feature variables also. As you can see we have three types of variables, with the bulk falling in the first group, then the second group and so on:\n",
    "\n",
    "1. **Count** variables of a *discrete*, *quantitative* nature.\n",
    "\n",
    "2. **Categorical** variables of a qualitative nature.\n",
    "\n",
    "3. **Binary** (**dichotomous**) variables of a categorical nature.\n",
    "\n",
    "The categorical variables are all lists of varying lengths of *places* and therefore are not in the appropriate form for machine learning. Once I create them I will actually *one-hot-encode* them into binary variables and discard the lists. You may ask why the one-hot-encoding is done with categorical yes / no values rather than 0 / 1 values? It is because the algorithms I will be processing the data with would treat 0 / 1 values as quantitive in nature which is clearly not what is desired. Essentially I will be left with two variable types, just binary variables and counts. OK time to go ahead and create the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(physicists, nobel_physicists, nobel_chemists,\n",
    "                   places, nationalities):\n",
    "    \"\"\"Build features for the physicists.\n",
    "\n",
    "    Args:\n",
    "        physicists (pandas.DataFrame): Physicists dataframe.\n",
    "        nobel_physicists (pandas.DataFrame): Nobel Physics\n",
    "            Laureate dataframe.\n",
    "        nobel_chemists (pandas.DataFrame): Nobel Chemistry\n",
    "            Laureate dataframe.\n",
    "        places (pandas.DataFrame): Places dataframe.\n",
    "        nationality (pandas.DataFrame): Nationalies dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Features dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = physicists.copy()[['fullName', 'name', 'gender']].rename(\n",
    "        mapper={'fullName': 'full_name'}, axis='columns')\n",
    "    features['num_years_lived'] = _build_num_years_lived(physicists.birthDate,\n",
    "                                                         physicists.deathDate)\n",
    "    \n",
    "    _build_physics_subfield_features(features, physicists)\n",
    "    _build_num_laureates_features(features, physicists,\n",
    "                                  nobel_physicists, nobel_chemists)\n",
    "    \n",
    "    _build_citizenship_features(features, physicists, nationalities)\n",
    "    \n",
    "    _build_places_features(features, physicists, places)\n",
    "    \n",
    "    features = _binarize_list_features(features)\n",
    "\n",
    "    features = features.drop('name', axis='columns')\n",
    "    return features\n",
    "\n",
    "\n",
    "def _build_physics_subfield_features(features, physicists):\n",
    "    features_to_build = {\n",
    "        'is_theoretical_physicist': {'categories': 'Theoretical physicists',\n",
    "                                     'others': 'theoretical physic'},\n",
    "        'is_experimental_physicist': {'categories': 'Experimental physicists',\n",
    "                                      'others': 'experimental physic'},\n",
    "        'is_astronomer': {'categories': 'astronomers',\n",
    "                          'others': 'astronom'}\n",
    "    }\n",
    "    \n",
    "    for feature, search_terms in features_to_build.items():\n",
    "        features[feature] = _build_physics_subfield(\n",
    "            physicists.categories, physicists.field, physicists.description,\n",
    "            physicists.comment, search_terms=search_terms)\n",
    "    \n",
    "\n",
    "\n",
    "def _build_num_laureates_features(features, physicists, nobel_physicists,\n",
    "                                  nobel_chemists):\n",
    "    features_to_build = {\n",
    "        'laureate_academic_advisors': 'academicAdvisor',\n",
    "        'laureate_doctoral_advisors': 'doctoralAdvisor',\n",
    "        'laureate_doctoral_students': 'doctoralStudent',\n",
    "        'laureate_notable_students': 'notableStudent',\n",
    "        'laureate_children': 'child',\n",
    "        'laureate_parents': 'parent',\n",
    "        'laureate_spouses': 'spouse',\n",
    "        'laureate_influenced': 'influenced',\n",
    "        'laureate_influenced_by': 'influencedBy'\n",
    "    }\n",
    "    \n",
    "    for feature, relation in features_to_build.items():\n",
    "        features['num_physics_' + feature] = _build_num_laureates(\n",
    "            physicists[relation], nobel_physicists.Laureate, nobel_physicists.name)\n",
    "        features['num_chemistry_' + feature] = _build_num_laureates(\n",
    "            physicists[relation], nobel_chemists.Laureate, nobel_chemists.name)\n",
    "\n",
    "\n",
    "    \n",
    "def _build_places_features(features, physicists, places):\n",
    "    features_to_build = {\n",
    "        'birth_country_alpha_3_codes': 'birthPlace',\n",
    "        'birth_continent_codes': 'birthPlace',\n",
    "        'death_country_alpha_3_codes': 'deathPlace',\n",
    "        'death_continent_codes': 'deathPlace',\n",
    "        'residence_country_alpha_3_codes': 'residence',\n",
    "        'residence_continent_codes': 'residence',\n",
    "        'alma_mater': 'almaMater',\n",
    "        'alma_mater_country_alpha_3_codes': 'almaMater',\n",
    "        'alma_mater_continent_codes': 'almaMater',\n",
    "        'workplaces': 'workplaces',\n",
    "        'workplaces_country_alpha_3_codes': 'workplaces',\n",
    "        'workplaces_continent_codes': 'workplaces'\n",
    "    }\n",
    "    \n",
    "    for feature, place in features_to_build.items():\n",
    "        code = 'countryAlpha3Code'\n",
    "        if 'continent' in feature:\n",
    "            code = 'continentCode'\n",
    "            \n",
    "        if feature in ['alma_mater', 'workplaces']:\n",
    "            features[feature] = physicists[place].apply(\n",
    "                _get_alma_mater_or_workplaces)           \n",
    "        else:\n",
    "            features[feature] = _build_places_codes(\n",
    "                physicists[place], places.fullName, places[code])\n",
    "        features['num_' + feature] = features[feature].apply(len)\n",
    "\n",
    "\n",
    "    \n",
    "def _build_citizenship_features(features, physicists, nationalities):\n",
    "    citizenship = physicists.citizenship.apply(\n",
    "        _get_citizenship_codes, args=(nationalities,))\n",
    "    nationality = physicists.nationality.apply(\n",
    "        _get_citizenship_codes, args=(nationalities,))\n",
    "    citizenship_description = physicists.description.apply(\n",
    "        _get_citizenship_codes, args=(nationalities,))\n",
    "    features['citizenship_country_alpha_3_codes'] = (\n",
    "        (citizenship + nationality + citizenship_description).apply(\n",
    "            lambda ctz: list(sorted(set(ctz)))))\n",
    "    features['num_citizenship_country_alpha_3_codes'] = (\n",
    "        features.citizenship_country_alpha_3_codes.apply(len))\n",
    "    features['citizenship_continent_codes'] = (\n",
    "        features.citizenship_country_alpha_3_codes.apply(\n",
    "            lambda al3: list(sorted({country_alpha2_to_continent_code(\n",
    "                country_alpha3_to_country_alpha2(cd)) for cd in al3}))))\n",
    "    features['num_citizenship_continent_codes'] = (\n",
    "        features.citizenship_continent_codes.apply(len))\n",
    "\n",
    "\n",
    "\n",
    "def _binarize_list_features(features):\n",
    "    # union of places and citizenship (without the counts)\n",
    "    series_to_binarize = {\n",
    "        'birth_country_alpha_3_codes': 'born_in_',\n",
    "        'birth_continent_codes': 'born_in_',\n",
    "        'death_country_alpha_3_codes': 'died_in_',\n",
    "        'death_continent_codes': 'died_in_',\n",
    "        'residence_country_alpha_3_codes': 'lived_in_',\n",
    "        'residence_continent_codes': 'lived_in_',\n",
    "        'alma_mater': 'alumnus_of_',\n",
    "        'alma_mater_country_alpha_3_codes': 'alumnus_in_',\n",
    "        'alma_mater_continent_codes': 'alumnus_in_',\n",
    "        'workplaces': 'worked_at_',\n",
    "        'workplaces_country_alpha_3_codes': 'worked_in_',\n",
    "        'workplaces_continent_codes': 'worked_in_',\n",
    "        'citizenship_country_alpha_3_codes': 'citizen_of_',\n",
    "        'citizenship_continent_codes': 'citizen_in_'\n",
    "    }\n",
    "        \n",
    "    for series, prefix in series_to_binarize.items():\n",
    "        binarized = _binarize_list_feature(features[series], prefix)\n",
    "        features = features.drop(series, axis='columns').join(binarized)\n",
    "    return features\n",
    "    \n",
    "    \n",
    "\n",
    "def _build_num_years_lived(birth_date, death_date):\n",
    "    death_date_no_nan = death_date.apply(_date_no_nan)\n",
    "    birth_date_no_nan = birth_date.apply(_date_no_nan)\n",
    "    years_lived = ((death_date_no_nan - birth_date_no_nan) / pd.to_timedelta(1, 'Y'))\n",
    "    return years_lived.astype('int64')\n",
    "\n",
    "\n",
    "def _build_physics_subfield(categories, field, description, comment, search_terms):\n",
    "    cat_theoretical_physicist = categories.apply(\n",
    "        lambda cat: search_terms['categories'] in cat)\n",
    "    field_theoretical_physicist = field.apply(\n",
    "        lambda fld: search_terms['others'] in fld.lower() if isinstance(fld, str)\n",
    "        else False)\n",
    "    desc_theoretical_physicist = description.apply(\n",
    "        lambda desc: search_terms['others'] in desc.lower() if isinstance(desc, str)\n",
    "        else False)\n",
    "    comm_theoretical_physicist = description.apply(\n",
    "        lambda comm: search_terms['others'] in comm.lower() if isinstance(comm, str)\n",
    "        else False)\n",
    "    subfield = (cat_theoretical_physicist |\n",
    "                field_theoretical_physicist |\n",
    "                desc_theoretical_physicist |\n",
    "                comm_theoretical_physicist)\n",
    "    subfield = subfield.apply(lambda val: 'yes' if val == True else 'no')\n",
    "    return subfield\n",
    "\n",
    "\n",
    "def _binarize_list_feature(series, prefix):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binarized = pd.DataFrame(\n",
    "        mlb.fit_transform(series),\n",
    "        columns=[prefix + class_.replace(' ', '_') for class_ in mlb.classes_],\n",
    "        index=series.index)\n",
    "    binarized = binarized.applymap(lambda val: 'yes' if val == 1 else 'no')\n",
    "    return binarized\n",
    "    \n",
    "\n",
    "\n",
    "def _build_num_laureates(series, laureates, names):\n",
    "    laureate_names = series.apply(_get_nobel_laureates,\n",
    "                                  args=(laureates, names))\n",
    "    return laureate_names.apply(len)\n",
    "\n",
    "\n",
    "def _build_places_codes(places_in_physicists, full_name_in_places, places_codes):\n",
    "    codes = places_in_physicists.apply(_get_places_codes,\n",
    "                                       args=(full_name_in_places, places_codes))\n",
    "    return codes\n",
    "\n",
    "\n",
    "def _get_alma_mater_or_workplaces(cell):\n",
    "    if isinstance(cell, float):\n",
    "        return list()\n",
    "    \n",
    "    places = set()\n",
    "    places_in_cell = cell.split('|')\n",
    "    for place_in_cell in places_in_cell:\n",
    "        # group colleges of University of Oxford and University of Cambridge\n",
    "        # with their respective parent university\n",
    "        if place_in_cell.endswith(', Cambridge'):\n",
    "            places.add('University of Cambridge')\n",
    "        elif place_in_cell.endswith(', Oxford'):\n",
    "            places.add('University of Oxford')\n",
    "        else:\n",
    "            places.add(place_in_cell)\n",
    "    \n",
    "    places = list(places)\n",
    "    places.sort(key=locale.strxfrm)\n",
    "    return places\n",
    "\n",
    "\n",
    "def _get_citizenship_codes(series, nationalities):\n",
    "    alpha_2_codes = nationality_to_alpha2_code(series, nationalities)\n",
    "    if isinstance(alpha_2_codes, float):\n",
    "        return list()\n",
    "    alpha_2_codes = alpha_2_codes.split('|')\n",
    "    alpha_3_codes = [country_name_to_country_alpha3(\n",
    "        country_alpha2_to_country_name(alpha_2_code))\n",
    "                     for alpha_2_code in alpha_2_codes]\n",
    "    return alpha_3_codes\n",
    "\n",
    "\n",
    "def _get_nobel_laureates(cell, laureates, names):\n",
    "    laureates_in_cell = set()\n",
    "    \n",
    "    if isinstance(cell, str):\n",
    "        # assume the same name if only differs by a hyphen\n",
    "        # or whitespace at front or end of string\n",
    "        values = cell.strip().replace('-', ' ').split('|')\n",
    "        for value in values:\n",
    "            if value in laureates.values:\n",
    "                laureates_in_cell.add(value)\n",
    "            if names.str.contains(value, regex=False).sum() > 0:\n",
    "                laureates_in_cell.add(value)\n",
    "                    \n",
    "    laureates_in_cell = list(laureates_in_cell)\n",
    "    return laureates_in_cell\n",
    "\n",
    "    \n",
    "def _get_places_codes(cell, full_name_in_places, places_codes):\n",
    "    codes = set()\n",
    "\n",
    "    if isinstance(cell, str):\n",
    "        places = cell.split('|')\n",
    "        for place in places:\n",
    "            code_indices = full_name_in_places[\n",
    "                full_name_in_places == place].index\n",
    "            assert(len(code_indices) <= 1)\n",
    "            if len(code_indices) != 1:\n",
    "                continue\n",
    "            code_index = code_indices[0]\n",
    "            codes_text = places_codes[code_index]\n",
    "            if isinstance(codes_text, float):\n",
    "                continue\n",
    "            codes_in_cell = codes_text.split('|')\n",
    "            for code_in_cell in codes_in_cell:\n",
    "                if code_in_cell:\n",
    "                    codes.add(code_in_cell)\n",
    "\n",
    "    codes = list(codes)\n",
    "    codes.sort()\n",
    "    return codes\n",
    "    \n",
    "\n",
    "def _date_no_nan(date):\n",
    "    if isinstance(date, str):\n",
    "        return datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    return datetime.now().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_physicists_features = build_features(train_physicists, nobel_physicists,\n",
    "                                           nobel_chemists, places, nationalities)\n",
    "assert((len(train_physicists_features) == len(train_physicists)))\n",
    "assert(len(train_physicists_features.columns) == 779)\n",
    "train_physicists_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_physicists_features = build_features(test_physicists, nobel_physicists,\n",
    "                                          nobel_chemists, places, nationalities)\n",
    "assert((len(test_physicists_features) == len(test_physicists)))\n",
    "assert(len(test_physicists_features.columns) == 663)\n",
    "test_physicists_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold on a second, there are less features for the test set than for the training set! Let's inspect the dataframe columns to see the difference. The difference is obviously due to the one-hot encoding as there are many differing country codes, workplaces, educational institutions etc. in the training and test sets. Some of this is due to the way that the data was sampled. For instance, the `died_in_[country_code]` features cannot possibly appear in the test set features since all the physicists are still alive. However, the majority of differences are due to the sheer variability in the data, which shows how difficult learning may be in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_cols = set(train_physicists_features.columns.values)\n",
    "test_features_cols = set(test_physicists_features.columns.values)\n",
    "feature_cols_difference = train_features_cols.difference(test_features_cols)\n",
    "display(feature_cols_difference)\n",
    "len(feature_cols_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But which and how many features are actually in common between the training and test sets? Under half of the features that are in the training set are in common. Unsurprisingly, these are the main educational institutions, workplaces and countries that are associated with physics research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_intersection = train_features_cols.intersection(test_features_cols)\n",
    "display(feature_cols_intersection)\n",
    "len(feature_cols_intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since any machine models I build will be evaluated on the test set, the tempting thing to do is to reduce the features to the common set of features between the training and test sets. However, this would clearly be *data snooping* (cheating) since the test set is meant to be unseen data. The other issue is if half of the features in the training set are thrown away and new examples come along with those exact features, the model would not be able to leverage this information. So the only logical thing to do is to ensure that the test set features are identical to the full set of features in the training set. And yes, this does mean that over half the test set features will consist of binary columns in which the values are all \"no\". Let's go ahead and do this now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_test_features_with_training_features(\n",
    "    test_features, train_features):\n",
    "    \"\"\"Synchronize test features dataframe with train features for physicists.\n",
    "    \n",
    "    The test features dataframe is changed so that its columns\n",
    "    match those in the training features dataframe. The union of\n",
    "    the columns in the training and test features is first taken\n",
    "    and then columns present in the training set that are not\n",
    "    present in the test set are joined with it. These columns are\n",
    "    filled with \"no\" values. This method should be called after\n",
    "    `build_features`.\n",
    "\n",
    "    Args:\n",
    "        physicists (pandas.DataFrame): Physicists dataframe.\n",
    "        nobel_physicists (pandas.DataFrame): Nobel Physics\n",
    "            Laureate dataframe.\n",
    "        nobel_chemists (pandas.DataFrame): Nobel Chemistry\n",
    "            Laureate dataframe.\n",
    "        places (pandas.DataFrame): Places dataframe.\n",
    "        nationality (pandas.DataFrame): Nationalies dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Test features dataframe.\n",
    "        \n",
    "        Columns are identical to the columns in the training\n",
    "        features dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_features_cols = set(train_features.columns.values)\n",
    "    test_features_cols = set(test_features.columns.values)\n",
    "    feature_cols_intersection = train_features_cols.intersection(\n",
    "        test_features_cols)\n",
    "    feature_cols_difference = train_features_cols.difference(\n",
    "        test_features_cols)\n",
    "    \n",
    "    test_features_synced = test_features.copy()\n",
    "    test_features_synced = test_features_synced[\n",
    "        list(feature_cols_intersection)]\n",
    "    shape=(len(test_features_synced), len(feature_cols_difference))\n",
    "    features_to_pad = pd.DataFrame(np.full(shape, 'no'),\n",
    "                                   columns=feature_cols_difference)\n",
    "    test_features_synced = test_features_synced.join(features_to_pad)\n",
    "    return test_features_synced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_physicists_features = sync_test_features_with_training_features(\n",
    "    test_physicists_features, train_physicists_features)\n",
    "assert(sorted(test_physicists_features.columns) == sorted(\n",
    "    train_physicists_features.columns))\n",
    "assert((len(test_physicists_features) == len(test_physicists)))\n",
    "test_physicists_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better now. \n",
    "\n",
    "It is clear to see that the one-hot encoding has tremendously increased the dimensionality of the problem. There are now 778 features (excluding the `full_name`) for 540 observations in the training set and 387 observations in the test set! Any model that is fit to such data would clearly be extremely prone to overfitting, so a dimensionality reduction is clearly needed on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting the Data\n",
    "\n",
    "Now I have the training and test features dataframes I'll persist them for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_physicists_features = train_physicists_features.reindex(\n",
    "    sorted(train_physicists_features.columns), axis='columns')\n",
    "train_physicists_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_physicists_features = test_physicists_features.reindex(\n",
    "    sorted(test_physicists_features.columns), axis='columns')\n",
    "test_physicists_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_physicists_features.to_csv('../data/processed/train-features.csv',\n",
    "                                 index=False)\n",
    "test_physicists_features.to_csv('../data/processed/test-features.csv',\n",
    "                                index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a quick sanity check to make sure the data is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_disk = pd.read_csv('../data/processed/train-features.csv')\n",
    "assert(train_on_disk.equals(train_physicists_features))\n",
    "test_on_disk = pd.read_csv('../data/processed/test-features.csv')\n",
    "assert(test_on_disk.equals(test_physicists_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
